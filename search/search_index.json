{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Faculty Sandbox","text":"<p>Quick Links: Resources Hub | Use Cases | Orientation | Sitemap | SPACE Sandbox</p> <p>Welcome to the Faculty Sandbox. This is the starting point for the GENAI Sandbox documentation, examples, and workshops you can use to run explorations and prepare orientation materials.</p>"},{"location":"#start-here","title":"Start Here","text":"<ul> <li>Resource Hub: Resources hub \u2013 status, action items, guardrails, and exemplar pointers.</li> <li>Orientation Playbook: orientation-outline.md \u2013 agenda and demo plan.</li> <li>Use Case Menu: faculty-sandbox-use-cases.md \u2013 active pilots, archived references, emerging ideas.</li> <li>Communications Draft: sandbox-docs-rollout.md \u2013 announcement outline and next steps.</li> </ul>"},{"location":"#templates-quickstarts","title":"Templates &amp; Quickstarts","text":"<ul> <li>Faculty template: faculty-sandbox-template.md</li> <li>Quickstart outline: quickstart-outline.md</li> <li>Workshop plans: workshops/ (template spine, invite, pre-read)</li> </ul>"},{"location":"#simulations","title":"Simulations","text":"<ul> <li>Humanities \u2013 quickstart | simulation</li> <li>Industrial Design \u2013 quickstart | simulation</li> <li>Physics MCQ \u2013 quickstart | simulation</li> <li>CS Code Review \u2013 quickstart | simulation</li> <li>Shared exemplars \u2013 workflow snapshot | verification log</li> <li>Observations log \u2013 faculty simulation notes (Internal coordination document)</li> </ul>"},{"location":"#student-sandbox-space","title":"Student Sandbox (SPACE)","text":"<ul> <li>Visit the dedicated SPACE portal: space/index.md</li> <li>Foundational project kit (quickstart, template, examples)</li> <li>AI Making Challenge kit (Prompt &amp; Validate quickstart, template, sample projects)</li> </ul>"},{"location":"#archives-background","title":"Archives &amp; Background","text":"<ul> <li>Brainstorming session results: Internal coordination document</li> <li>Archive of prior guides/examples: docs/examples/archive/</li> </ul>"},{"location":"#feedback-next-steps","title":"Feedback &amp; Next Steps","text":"<ul> <li>Track structural updates or propose improvements in architect brief (Internal coordination document)</li> <li>Use monthly pulses and workshop sessions to gather feedback before rollout.</li> </ul>"},{"location":"quickstart-outline/","title":"Quickstart","text":"<p>Back to Faculty Sandbox | Resources: resources hub | Visit SPACE Sandbox</p>"},{"location":"quickstart-outline/#genai-sandbox-quickstart-outline-draft","title":"GENAI Sandbox Quickstart Outline (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"quickstart-outline/#1-set-your-exploration-goal","title":"1. Set Your Exploration Goal","text":"<ul> <li>Identify a teaching/learning challenge you want to experiment with (e.g., faster feedback, diverse exemplars, study supports).</li> <li>Write one concrete outcome for the prototype window (2-month horizon).</li> <li>Note the audience you have in mind (your class, colleague group, or self-directed learners).</li> </ul>"},{"location":"quickstart-outline/#2-map-the-sandbox-run","title":"2. Map the Sandbox Run","text":"<ul> <li>List 2\u20133 AI tools or features you intend to trial.</li> <li>Sketch a lightweight workflow snapshot table (Step \u2192 AI assist \u2192 Human judgment).</li> <li>Plan how you will test the idea quickly (e.g., small batch of materials, pilot activity, student volunteer group).</li> </ul>"},{"location":"quickstart-outline/#3-experiment-capture-learnings","title":"3. Experiment &amp; Capture Learnings","text":"<ul> <li>Run the workflow, capturing what you tried, what happened, and any adjustments.</li> <li>Log prompts, outputs, and commentary so you can reproduce or compare iterations.</li> <li>Highlight unexpected wins, blockers, or questions for future exploration.</li> </ul>"},{"location":"quickstart-outline/#4-prep-your-share-out-artifact","title":"4. Prep Your Share-Out Artifact","text":"<ul> <li>Select a format that fits your audience (slide deck, walkthrough, annotated syllabus, SPACE guide, etc.).</li> <li>Summarize the exploration story: goal \u2192 workflow \u2192 outcomes \u2192 next exploration steps.</li> <li>Include at least one exemplar artifact or snapshot that shows the AI + human partnership.</li> </ul>"},{"location":"quickstart-outline/#5-reflection-next-steps","title":"5. Reflection &amp; Next Steps","text":"<ul> <li>Answer the three check-in prompts: What shifted? How did AI help/hurt? What will you keep or change?</li> <li>List the next experiment you would run given more time.</li> <li>Capture any asks for the community-of-practice pulse (feedback, resources, ideas).</li> </ul>"},{"location":"quickstart-outline/#6-safety-guardrails-keep-it-simple","title":"6. Safety Guardrails (Keep It Simple)","text":"<ul> <li>Confirm you followed integrity &amp; transparency guidelines (see Faculty template guardrails).</li> <li>Note how you verified key AI outputs (brief bullets; no long report needed).</li> <li>Flag any policy questions for coordination follow-up (note them in resources hub).</li> </ul> <p>Use this outline to keep the sandbox centered on experimentation. Detailed templates will plug into these steps after the drafting workshop.</p>"},{"location":"sitemap/","title":"Sandbox Site Map","text":"<p>Back to Faculty Sandbox</p> <p>Quick reference to every major resource in the GENAI Sandbox repo.</p>"},{"location":"sitemap/#core-docs","title":"Core Docs","text":"<ul> <li><code>docs/index.md</code> \u2014 Faculty Sandbox landing page linking all resources.</li> <li>Resources hub \u2014 Running status board, guardrails, exemplar pointers.</li> <li><code>docs/orientation/orientation-outline.md</code> \u2014 Orientation agenda + demo inserts.</li> <li><code>docs/use-cases/faculty-sandbox-use-cases.md</code> \u2014 Menu of active/backlog faculty pilots.</li> <li>Product spec framing the documentation overhaul \u2014 Internal planning document.</li> </ul>"},{"location":"sitemap/#templates-quickstarts","title":"Templates &amp; Quickstarts","text":"<ul> <li><code>docs/quickstart-outline.md</code> \u2014 Faculty quickstart steps for experiments.</li> <li><code>docs/guides/faculty-sandbox-template.md</code> \u2014 Exploration template to capture goals \u2192 workflow \u2192 reflection.</li> <li><code>docs/guides/template-spine-outline.md</code> \u2014 Shared spine elements for template drafting.</li> <li><code>docs/guides/space-student-guide.md</code> \u2014 Faculty view of student self-directed template.</li> </ul>"},{"location":"sitemap/#workshops-communications","title":"Workshops &amp; Communications","text":"<ul> <li><code>docs/workshops/template-spine-workshop.md</code> \u2014 Live session agenda for drafting the spine.</li> <li><code>docs/workshops/template-spine-invite.md</code> \u2014 Calendar invite copy + pre-read summary.</li> <li><code>docs/workshops/template-spine-preread.md</code> \u2014 Participant prep checklist and goals.</li> <li><code>docs/communications/sandbox-docs-rollout.md</code> \u2014 Announcement email draft for rollout.</li> </ul>"},{"location":"sitemap/#faculty-simulations","title":"Faculty Simulations","text":"<ul> <li>Humanities \u2014 quickstart / simulation.</li> <li>Industrial Design \u2014 quickstart / simulation.</li> <li>Physics MCQ \u2014 quickstart / simulation.</li> <li>CS Code Review \u2014 quickstart / simulation.</li> <li>Observations log \u2014 faculty simulation notes (Internal coordination document).</li> </ul>"},{"location":"sitemap/#shared-exemplars-archives","title":"Shared Exemplars &amp; Archives","text":"<ul> <li>Workflow snapshot example \u2014 <code>docs/examples/shared/workflow-snapshot-example.md</code>.</li> <li>Verification log example \u2014 <code>docs/examples/shared/verification-log-example.md</code>.</li> <li>Archived simulations/templates \u2014 see the Markdown files under <code>docs/examples/archive/</code> for legacy references.</li> </ul>"},{"location":"sitemap/#student-space-sandbox","title":"Student / SPACE Sandbox","text":"<ul> <li><code>space/index.md</code> \u2014 SPACE Sandbox entry point.</li> <li>Foundational track \u2014 quickstart / template / nursing example.</li> <li>AI Making Challenge \u2014 quickstart / template / examples.</li> <li>Coordinator notes \u2014 Foundational / AI Making (Internal coordination documents).</li> </ul>"},{"location":"sitemap/#handovers-background","title":"Handovers &amp; Background","text":"<ul> <li>JT action list for content/timeline finalization \u2014 Internal coordination document.</li> <li>Summary of structure goals &amp; requests \u2014 Internal coordination document.</li> <li>Role-playing + SCAMPER session record \u2014 Internal coordination document.</li> </ul> <p>Use this map to jump anywhere without hunting through folders.</p>"},{"location":"communications/call_for_participation/","title":"Call for Participation \u2014 GENAI Sandbox (College Edition)","text":"<p>What: A 12\u201316 week, hands-on program where faculty\u2013student teams prototype AI\u2011enhanced teaching/learning artifacts and share them at a cross\u2011disciplinary showcase.</p> <p>Who: College educators (any discipline) and students. No prior AI experience required.</p> <p>Why: Explore practical AI use in courses, co-develop assessment strategies, and publish classroom-ready exemplars.</p> <p>Partners: AI Initiative \u00b7 SPACE (student enrichment) \u00b7 Faculty Learning Communities (FLCs)</p>"},{"location":"communications/call_for_participation/#key-dates-adjust-as-needed","title":"Key Dates (adjust as needed)","text":"<ul> <li>Applications open: [DATE]</li> <li>Info session: [DATE]</li> <li>Kickoff: [DATE]</li> <li>Clinics: weekly (60 minutes, recorded)</li> <li>Showcase: [DATE]</li> </ul> <p>Time commitment: ~2\u20133 hrs/week/team average.</p>"},{"location":"communications/call_for_participation/#what-youll-produce","title":"What you\u2019ll produce","text":"<ul> <li>1+ artifact (assignment/module/demo/dataset + usage notes)</li> <li>AI disclosure &amp; integrity checklist</li> <li>Assessment strategy and reflection</li> </ul>"},{"location":"communications/call_for_participation/#support-provided","title":"Support provided","text":"<ul> <li>Small number of shared tool licenses (edu/free-first)</li> <li>Weekly clinics + office hours</li> <li>Accessibility and Integrity quick reviews</li> <li>Showcase with SPACE + FLCs (refreshments provided)</li> </ul>"},{"location":"communications/call_for_participation/#selection-criteria","title":"Selection criteria","text":"<ul> <li>Cross-disciplinary spread across the college</li> <li>Clear student benefit &amp; course alignment</li> <li>Feasible scope in 12\u201316 weeks</li> <li>Commitment to publish under CC-BY</li> </ul>"},{"location":"communications/call_for_participation/#expectations","title":"Expectations","text":"<ul> <li>Attend kickoff + most clinics (recordings available)</li> <li>Keep a brief prompt/process log</li> <li>Complete disclosure + integrity checklist</li> <li>Present at the showcase</li> <li>Share artifact under CC-BY</li> </ul>"},{"location":"communications/call_for_participation/#apply-google-form-fields","title":"Apply (Google Form fields)","text":"<ul> <li>Team members (faculty + students) &amp; departments</li> <li>Course context + target learning outcomes</li> <li>Artifact idea (1\u20132 paragraphs)</li> <li>Risks/constraints (data, ethics, tech)</li> <li>Accessibility considerations (if any)</li> </ul> <p>Questions? Contact: [NAME, EMAIL]</p>"},{"location":"communications/sandbox-docs-rollout/","title":"Rollout Draft","text":"<p>Back to Faculty Sandbox | Resources: resources.md | Orientation: orientation-outline.md</p>"},{"location":"communications/sandbox-docs-rollout/#genai-sandbox-documentation-refresh-rollout-draft","title":"GENAI Sandbox Documentation Refresh \u2013 Rollout Draft","text":"<p>Audience: Faculty cohort, SPACE leads, coordination touchpoints Timing: Send once review feedback returns (target early Oct 2025)</p>"},{"location":"communications/sandbox-docs-rollout/#subject-options","title":"Subject Options","text":"<ol> <li>\"Ready to explore: new GENAI Sandbox templates &amp; quickstart\"</li> <li>\"Sandbox refresh: streamlined docs for your fall experiments\"</li> </ol>"},{"location":"communications/sandbox-docs-rollout/#message-outline","title":"Message Outline","text":"<p>Opening (why now) - Highlight the shift to exploration-first templates. - Mention the sandbox window (prototype runs before classroom deployment and SPACE projects through May 2026).</p> <p>What\u2019s new - Streamlined faculty exploration template (<code>docs/guides/faculty-sandbox-template.md</code>). - SPACE self-directed project guide (<code>docs/guides/space-student-guide.md</code>). - Quickstart outline (<code>docs/quickstart-outline.md</code>) plus exemplar tables (workflow snapshot, verification log) and persona simulations (humanities, industrial design, physics MCQ, CS code review). - Resource hub (<code>docs/resources.md</code>) as the single entry point.</p> <p>How to get started - Pick an exploration goal using the quickstart. - Join the Oct 22 workshop (link to calendar invite once sent). - Log experiments with the new workflow/verification tables.</p> <p>Support &amp; guardrails - Monthly pulse for questions; learning strategist drop-ins if needed. - Light checklist reminders for transparency, privacy, licensing. - Archive link (<code>docs/archive/brownfield-templates-2024/</code>) available for deeper reference.</p> <p>Call to action - Ask recipients to confirm they\u2019ve skimmed the quickstart and templates. - Encourage sharing early artifacts for exemplars. - Provide contact for feedback (JT + PM alias).</p>"},{"location":"communications/sandbox-docs-rollout/#draft-body-copy","title":"Draft Body Copy","text":"<p>Hi all,</p> <p>The GENAI Sandbox docs are refreshed and ready for your fall experiments. We heard you: you wanted less compliance paperwork and more space to try ideas. The new exploration-first templates are live, along with a quickstart guide and examples to make documenting straightforward.</p> <p>Start here: <code>docs/index.md</code> (Faculty Sandbox) \u2013 links to resources, templates, quickstarts, and exemplar tables. <code>docs/resources.md</code> captures ongoing action items. Pick an exploration goal, drop it into the template, and capture what you learn along the way.</p> <p>What\u2019s changed: - A lean Goal \u2192 Workflow \u2192 Evidence \u2192 Reflection \u2192 Guardrails flow for faculty projects (<code>docs/guides/faculty-sandbox-template.md</code>). - A matching SPACE self-directed guide for students running through May 2026 (<code>docs/guides/space-student-guide.md</code>). - Ready-to-use workflow and verification examples in shared exemplars and persona-specific folders under <code>docs/examples/faculty/</code>. - The brownfield archive lives at <code>docs/archive/brownfield-templates-2024/</code> if you need the old format for reference.</p> <p>Upcoming: We\u2019ll workshop the drafts together on Oct 22 (13:00\u201314:00 ET). Watch for the invite + pre-read; bring any terminology tweaks and early experiment ideas.</p> <p>Need support? Use the monthly pulse to flag questions. We\u2019re keeping guardrails light\u2014a quick checklist for transparency, data privacy, and licensing sits inside each template. If you\u2019re unsure about anything, reach out to JT or reply here.</p> <p>Let\u2019s make the sandbox a space to test, learn, and share before scaling to the classroom. Send over your first artifacts when they\u2019re ready so we can highlight exemplars.</p> <p>Thanks! \u2014 JT &amp; John</p>"},{"location":"communications/sandbox-docs-rollout/#next-steps","title":"Next Steps","text":"<ul> <li>[ ] Align on subject line</li> <li>[ ] Plug in workshop invite link once calendar hold is out</li> <li>[ ] Confirm reviewer feedback incorporated</li> <li>[ ] Send via coordination mailing list / SPACE channel</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/","title":"Quickstart","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/cs-code-review/quickstart/#faculty-simulation-computer-science-persona-quickstart","title":"Faculty Simulation \u2013 Computer Science Persona Quickstart","text":""},{"location":"examples/faculty/cs-code-review/quickstart/#persona-snapshot","title":"Persona Snapshot","text":"<ul> <li>Department: Computer Science (Intro to Programming)</li> <li>Instructor Goal: Provide rapid AI-assisted code review so students can unblock themselves before the instructor refines final guidance.</li> <li>Course Context: COMP 140 cohort of 32 students working through weekly lab assignments.</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#1-set-exploration-goal","title":"1. Set Exploration Goal","text":"<ul> <li>Challenge: Instructor and TAs spend hours giving repetitive feedback on common mistakes, delaying deeper coaching.</li> <li>Prototype Goal: Pilot a Claude/ChatGPT workflow that generates preliminary code feedback, letting students iterate independently before instructor review.</li> <li>Audience: Single instructor and one TA overseeing weekly labs; departmental interest in scaling if workflow proves effective.</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#2-map-the-sandbox-run","title":"2. Map the Sandbox Run","text":"<ul> <li>Tools to Trial: Claude (primary) or ChatGPT (backup) for code review prompts, GitHub Classroom submissions, shared Google Doc tracker.</li> <li>Workflow Snapshot Draft: Student submits lab code \u2192 AI review summary \u2192 student revision log \u2192 instructor refinement &amp; final comments.</li> <li>Rapid Test: Apply across two lab cycles (loops &amp; conditionals; basic data structures) with opt-in student participation.</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#3-experiment-capture-learnings","title":"3. Experiment &amp; Capture Learnings","text":"<ul> <li>Save prompts and AI responses per submission; log student revisions and instructor comments.</li> <li>Metrics: Time to unblock, number of AI suggestions accepted, instructor review time per submission, student confidence survey.</li> <li>Risks: AI suggesting incorrect fixes, students over-relying on AI, ensuring academic integrity (no solution leakage).</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#4-prep-share-out-artifact","title":"4. Prep Share-Out Artifact","text":"<ul> <li>Deliverable: Code review packet showing AI feedback, student response, and instructor refinements.</li> <li>Story: Initial submission \u2192 AI assist \u2192 student revisions \u2192 instructor wrap-up \u2192 outcome metrics.</li> <li>Evidence: Annotated code snippets, revision timestamps, quick survey results.</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#5-reflection-next-steps","title":"5. Reflection &amp; Next Steps","text":"<ul> <li>Questions: Did AI reduce turnaround time? Did students articulate understanding when addressing AI feedback?</li> <li>Next Experiment Idea: Extend to peer review workshops or integrate auto-generated practice exercises for common errors.</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#6-safety-guardrails","title":"6. Safety Guardrails","text":"<ul> <li>Integrity: AI feedback limited to hints/explanations; instructor validates critical fixes before release.</li> <li>Student data &amp; privacy: Anonymize submissions when storing prompts/responses; keep within course repository.</li> <li>Licensing: Confirm AI outputs meet institutional policy (no redistribution outside course).</li> </ul>"},{"location":"examples/faculty/cs-code-review/quickstart/#additional-notes","title":"Additional Notes","text":"<ul> <li>Special requirement: Department wants emerging code-review tools; this low-stakes run informs future adoption decisions.</li> <li>Coordination ask: Need lightweight template for logging AI feedback outcomes and instructor overrides.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/","title":"Simulation","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/cs-code-review/simulation/#genai-sandbox-faculty-exploration-template-cs-code-review-simulation","title":"GENAI Sandbox \u2013 Faculty Exploration Template (CS Code Review Simulation)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"examples/faculty/cs-code-review/simulation/#sandbox-overview","title":"Sandbox Overview","text":"<p>\"This sandbox concept is your space to explore AI-enhanced teaching before classroom deployment. Share what you learn, keep materials CC-BY where possible, and flag integrity questions during the monthly pulse. The checklist below keeps governance light; use it as a reminder, not a barrier.\"</p> <ul> <li>[x] Transparency: I can explain any AI-generated material included here.</li> <li>[x] Student data &amp; privacy: Submissions anonymized in stored prompts/responses.</li> <li>[x] Licensing: Claude/ChatGPT outputs used only within course; no external redistribution.</li> <li>Notes / Exceptions: Awaiting departmental green light for broader tool procurement.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#1-exploration-goal-snapshot","title":"1. Exploration Goal Snapshot","text":"<ul> <li>Goal (1\u20132 sentences): Test an AI-assisted code review workflow that helps students self-correct lab submissions before instructor feedback, freeing instructor time for deeper coaching.</li> <li>Intended audience: 32 students in COMP 140; managed by lead instructor and one TA.</li> <li>Why this matters now: Instructor spends ~4 hours per lab on repetitive feedback; students wait multiple days for revisions.</li> <li>Special requirements or constraints (accessibility, departmental needs, etc.): Maintain academic integrity (no full solutions); document AI vs. human feedback for committee review.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#2-workflow-experiment-log","title":"2. Workflow &amp; Experiment Log","text":"Step AI Assist Human Judgment Evidence / Notes 1 Student submits code via GitHub Classroom; Claude generates feedback on logic, style, and suggested next steps Student reviews AI comments, flags confusing points AI response + prompt stored in tracker 2 Student implements revisions, annotates changes in reflection log Instructor spot-checks AI suggestions, ensures no incorrect fixes Revision diff + student notes saved 3 If AI feedback seems off, student requests TA review; ChatGPT backup used if Claude unavailable TA/instructor corrects misinformation, adds targeted teaching points Override log documents human edits 4 Instructor provides final comments focusing on concepts not covered by AI or persistent misconceptions Final feedback merged into LMS gradebook Instructor summary and time spent recorded 5 Post-lab survey captures student confidence and perceived usefulness Instructor compiles results, compares to baseline Survey summary appended 6 Instructor updates workflow prompts/templates based on findings Share takeaways with department committee Iteration notes filed in sandbox log <ul> <li>Iteration notes: AI occasionally suggested changing loop boundaries incorrectly\u2014prompt updated to remind \u201csuggest fixes with explanation, do not alter logic unless verified.\u201d Students appreciated quick hints but needed guidance distinguishing suggestions vs. solutions.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#3-outputs-artifacts","title":"3. Outputs &amp; Artifacts","text":"<ul> <li>Artifact 1 (link / location): Code review packet (AI feedback, student revisions, instructor comments) \u2013 <code>examples/cs-codereview-sim-packet.pdf</code>.</li> <li>Artifact 2 (optional): AI feedback tracker template with override log.</li> <li>Supporting media or walkthrough: Short Loom showing how AI feedback feeds into GitHub Classroom review.</li> <li>Audience feedback captured (if any): 78% of students felt unblocked faster; instructor reported time per submission dropped from 12 to 6 minutes.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#4-reflection-check-in","title":"4. Reflection Check-In","text":"<ol> <li>What shifted during the sandbox run?</li> <li>Turnaround time halved; students submitted revisions within 12 hours vs. previous 48-hour average.</li> <li>How did AI help or hinder your approach?</li> <li>Helped by catching stylistic issues and suggesting test cases; hindered when explanations were verbose or hinted at full solutions.</li> <li>What will you keep, change, or try next?</li> <li>Keep AI-first review step; change prompts to emphasize \u201chint vs. solution\u201d; next, trial peer review layer using AI feedback as a starting point.</li> </ol>"},{"location":"examples/faculty/cs-code-review/simulation/#5-verification-snapshot","title":"5. Verification Snapshot","text":"Output / Decision How I verified it Confidence (low/med/high) AI feedback accuracy Spot-checked 10% of responses; corrected two logic misfires Medium Student reflection logs Reviewed for evidence of understanding vs. copying High Privacy compliance Confirmed anonymized storage, restricted drive access High <ul> <li>Follow-up questions for coordination (policy, feasibility, other constraints): Need clarity on long-term storage of AI feedback; evaluate department appetite for broader pilot.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#6-next-experiment-hooks","title":"6. Next Experiment Hooks","text":"<ul> <li>Next idea I want to explore: Introduce AI-generated practice snippets targeting top three recurring errors.</li> <li>Support I could use (community feedback, resources, tooling): Input from department on code-review tooling roadmap; templates from peer institutions.</li> <li>Planned share-out (department meeting, sandbox cohort session, etc.): Demo during CS faculty meeting and sandbox orientation showcase.</li> </ul>"},{"location":"examples/faculty/cs-code-review/simulation/#optional-persona-prompt-sidebar","title":"Optional Persona Prompt Sidebar","text":"<ul> <li>Starter prompts: \u201cReview this Python function for correctness and style; highlight potential logic errors without giving the full fix.\u201d</li> <li>Optimizer prompts: \u201cSuggest follow-up tests the student can run to validate edge cases; keep hints conceptual.\u201d</li> </ul> <p>Need inspiration? Check the shared exemplars in <code>docs/examples/shared/</code> for workflow and verification samples.</p>"},{"location":"examples/faculty/humanities/quickstart/","title":"Quickstart","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/humanities/quickstart/#faculty-simulation-humanities-persona-quickstart","title":"Faculty Simulation \u2013 Humanities Persona Quickstart","text":""},{"location":"examples/faculty/humanities/quickstart/#persona-snapshot","title":"Persona Snapshot","text":"<ul> <li>Department: Humanities (History of Ideas seminar)</li> <li>Instructor Goal: Help students interrogate AI-generated primary-source summaries while preserving critical analysis skills.</li> <li>Course Context: Liberal Arts module exploring enlightenment texts (360-DWP-xx); limited class time for close reading.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#1-set-exploration-goal","title":"1. Set Exploration Goal","text":"<ul> <li>Challenge: Students rely on AI summaries instead of engaging with original texts.</li> <li>Prototype Goal: Test a workflow where AI drafts comparative summaries and students annotate discrepancies during seminar prep.</li> <li>Audience: Cohort of 32 students in the Liberal Arts program (History of Ideas seminar).</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#2-map-the-sandbox-run","title":"2. Map the Sandbox Run","text":"<ul> <li>Tools to Trial: ChatGPT &amp; Claude (comparative summaries), Perplexity (source trails), Hypothes.is for annotations.</li> <li>Workflow Snapshot Draft: Present in template (steps: select text, AI compare, student annotation, reflection).</li> <li>Rapid Test: Use two upcoming readings (Kant + Wollstonecraft) over a two-week mini-cycle.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#3-experiment-capture-learnings","title":"3. Experiment &amp; Capture Learnings","text":"<ul> <li>Plan to log prompts and AI outputs in shared drive; track student annotation quality pre/post.</li> <li>Initial expectation: AI summaries surface structural themes; students identify nuance gaps.</li> <li>Risks: Over-reliance on AI phrasing; citation accuracy.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#4-prep-share-out-artifact","title":"4. Prep Share-Out Artifact","text":"<ul> <li>Deliverable: Slide deck + annotated sample showing student annotations vs. AI summary.</li> <li>Story: Goal \u2192 workflow \u2192 findings on student engagement \u2192 next tweak.</li> <li>Evidence: Screenshots of Hypothes.is threads, before/after reflection snippets.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#5-reflection-next-steps","title":"5. Reflection &amp; Next Steps","text":"<ul> <li>Questions: Did annotated workflow increase primary text references in discussion? What adjustments improve prompt specificity?</li> <li>Next Experiment Idea: Integrate AI-generated discussion starters validated by student teams.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#6-safety-guardrails","title":"6. Safety Guardrails","text":"<ul> <li>Integrity: Cross-check AI summary citations with original texts.</li> <li>Student data &amp; privacy: Archive annotations in FERPA-compliant folder; anonymize screenshots.</li> <li>Licensing: Use CC-BY slides; attribute AI outputs.</li> </ul>"},{"location":"examples/faculty/humanities/quickstart/#additional-notes","title":"Additional Notes","text":"<ul> <li>Special requirement: Departmental mandate to archive Hypothes.is threads each term and log accessibility compliance.</li> <li>Coordination ask: Request institution-backed Claude license to avoid personal accounts and ensure data retention policy alignment.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/","title":"Simulation","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/humanities/simulation/#genai-sandbox-faculty-exploration-template-humanities-simulation","title":"GENAI Sandbox \u2013 Faculty Exploration Template (Humanities Simulation)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"examples/faculty/humanities/simulation/#sandbox-overview","title":"Sandbox Overview","text":"<p>\"This sandbox concept is your space to explore AI-enhanced teaching before classroom deployment. Share what you learn, keep materials CC-BY where possible, and flag accessibility or integrity questions during the monthly pulse. The checklist below keeps governance light; use it as a reminder, not a barrier.\"</p> <ul> <li>[x] Transparency: I can explain any AI-generated material included here.</li> <li>[x] Student data &amp; privacy: I protected personal information and followed institutional data-use rules.</li> <li>[x] Licensing: Assets are CC-BY or note exceptions below.</li> <li>Notes / Exceptions: Perplexity output screenshot and Claude snippet attributed in slides.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#1-exploration-goal-snapshot","title":"1. Exploration Goal Snapshot","text":"<ul> <li>Goal (1\u20132 sentences): Help seminar students interrogate AI-generated primary-source summaries to deepen critical reading habits.</li> <li>Intended audience: 32 students in HIST 345 \u2013 History of Ideas seminar.</li> <li>Why this matters now: Students increasingly arrive with AI summaries and skip close reading, reducing discussion depth.</li> <li>Special requirements or constraints (accessibility, departmental needs, etc.): Department requires archiving annotated discussions each term; all materials must meet accessibility checklist.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#2-workflow-experiment-log","title":"2. Workflow &amp; Experiment Log","text":"Step AI Assist Human Judgment Evidence / Notes 1 ChatGPT &amp; Claude generate comparative summaries of Kant &amp; Wollstonecraft excerpts using instructor-provided prompts Instructor reviews summary for accuracy, flags misinterpretations Prompt saved in shared drive; AI output logged with version date 2 Perplexity supplies citation trail for supporting sources Instructor verifies citations, replaces any weak sources Citation list appended to workflow deck 3 Students annotate AI summary via Hypothes.is highlighting gaps or bias Instructor moderates annotations, adds guiding questions Screenshot of annotation thread; student names pseudonymized 4 Students craft mini-reflections comparing their interpretation to AI summary Instructor reviews reflections, tracks depth of textual references Sample reflections stored in portfolio 5 Cohort discussion uses annotated summary as scaffold Instructor captures key discussion insights, notes lingering misconceptions Discussion notes summarized in slide deck 6 Instructor updates prompt/summary workflow for next reading Instructor documents changes and rationale Iteration log maintained in quickstart notes <ul> <li>Iteration notes (adjustments, surprises, prompts worth saving): Initial Claude prompt over-emphasized stylistic analysis; revised to focus on argument structure. Students requested guidance on spotting omission of historical context\u2014added tip sheet.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#3-outputs-artifacts","title":"3. Outputs &amp; Artifacts","text":"<ul> <li>Artifact 1 (link / location): Slide deck with workflow snapshots and student annotation highlights (<code>examples/humanities-sim-deck.pdf</code> placeholder).</li> <li>Artifact 2 (optional): Annotated summary export (Hypothes.is PDF) stored in departmental archive.</li> <li>Supporting media or walkthrough: Loom video demo (to be recorded) walking through prompt revision.</li> <li>Audience feedback captured (if any): Post-seminar poll showed 78% felt more prepared for discussion; comments requested more transparent citation notes.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#4-reflection-check-in","title":"4. Reflection Check-In","text":"<ol> <li>What shifted during the sandbox run?</li> <li>Students referenced primary text passages 1.7\u00d7 more often in discussion compared to baseline; annotations exposed misconceptions early.</li> <li>How did AI help or hinder your approach?</li> <li>Helped by surfacing comparable themes quickly; hindered when AI glossed over historical context, requiring manual augmentation.</li> <li>What will you keep, change, or try next?</li> <li>Keep the annotation workflow; change citation verification to a shared student role; next, pilot AI-generated discussion starters vetted by student teams.</li> </ol>"},{"location":"examples/faculty/humanities/simulation/#5-verification-snapshot","title":"5. Verification Snapshot","text":"Output / Decision How I verified it Confidence (low/med/high) ChatGPT &amp; Claude comparative summary Cross-checked key claims with original texts; consulted secondary source for philosophical accuracy Medium Perplexity citation list Manually opened each source; replaced two weak references with peer-reviewed articles High Annotation exports Ensured student identifiers removed before sharing; confirmed archive permissions High <ul> <li>Follow-up questions for coordination (policy, feasibility, other constraints): Confirm FERPA-compliant retention of Hypothes.is exports; explore campus license for ChatGPT/Claude to avoid personal accounts.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#6-next-experiment-hooks","title":"6. Next Experiment Hooks","text":"<ul> <li>Next idea I want to explore: Student teams generate AI discussion prompts, then critique and refine before class.</li> <li>Support I could use (community feedback, resources, tooling): Sample prompts from other faculty; guidance on balancing AI vs. human commentary.</li> <li>Planned share-out (department meeting, sandbox cohort session, etc.): Share at sandbox cohort check-in and October humanities teaching circle.</li> </ul>"},{"location":"examples/faculty/humanities/simulation/#optional-persona-prompt-sidebar","title":"Optional Persona Prompt Sidebar","text":"<ul> <li>Starter prompts: \u201cWhat if AI handled first-pass summaries while students critique omissions?\u201d</li> <li>Optimizer prompts: \u201cHow can I validate philosophical claims faster without losing nuance?\u201d</li> </ul> <p>Need inspiration? Check the shared exemplars in <code>docs/examples/shared/</code> for workflow and verification samples.</p>"},{"location":"examples/faculty/industrial-design/quickstart/","title":"Quickstart","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/industrial-design/quickstart/#faculty-simulation-industrial-design-persona-quickstart","title":"Faculty Simulation \u2013 Industrial Design Persona Quickstart","text":""},{"location":"examples/faculty/industrial-design/quickstart/#persona-snapshot","title":"Persona Snapshot","text":"<ul> <li>Department: Industrial Design (Product Innovation Studio)</li> <li>Instructor Goal: Guide third-year students to use an LLM as a co-designer for early concept exploration while maintaining human-led prototyping decisions.</li> <li>Course Context: 14-week industrial design studio; teams deliver iterative prototypes for mobility-focused products.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#1-set-exploration-goal","title":"1. Set Exploration Goal","text":"<ul> <li>Challenge: Teams spend excessive time drafting concept briefs, leaving limited cycles for physical prototyping.</li> <li>Prototype Goal: Test a workflow where an LLM generates structured design briefs and constraint checklists that students refine before prototyping.</li> <li>Audience: 20 third-year industrial design students (five teams of four).</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#2-map-the-sandbox-run","title":"2. Map the Sandbox Run","text":"<ul> <li>Tools to Trial: GPT-5 (concept briefs, material suggestions), Rhino plugin with LLM prompt integration, Miro board for constraint mapping.</li> <li>Workflow Snapshot Draft: Ideation prompts \u2192 LLM-generated brief \u2192 team refinement \u2192 constraint checklist \u2192 prototyping sprint.</li> <li>Rapid Test: Apply to two-week sprint developing adaptive commuter accessories.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#3-experiment-capture-learnings","title":"3. Experiment &amp; Capture Learnings","text":"<ul> <li>Log prompts, LLM outputs, and edits within shared Miro board; capture rationale for human adjustments.</li> <li>Metrics: Time to finalized brief, number of prototyping iterations achieved, quality of constraint coverage.</li> <li>Risks: LLM suggesting infeasible materials; over-trusting specs without engineering validation.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#4-prep-share-out-artifact","title":"4. Prep Share-Out Artifact","text":"<ul> <li>Deliverable: Miro board export highlighting LLM prompts, student edits, and resulting prototype storyboard.</li> <li>Story: Problem framing \u2192 LLM collaboration \u2192 refined constraints \u2192 prototype outcomes \u2192 next sprint focus.</li> <li>Evidence: Annotated screenshots, spreadsheet tracking time saved, photos of quick prototypes.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#5-reflection-next-steps","title":"5. Reflection &amp; Next Steps","text":"<ul> <li>Questions: Did the LLM accelerate brief creation without reducing originality? Were constraint checklists comprehensive enough for prototyping? </li> <li>Next Experiment Idea: Integrate LLM-generated test scenarios evaluated against actual prototype performance.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#6-safety-guardrails","title":"6. Safety Guardrails","text":"<ul> <li>Integrity: Teams must document every LLM suggestion and indicate acceptance/rejection rationale.</li> <li>Student data &amp; privacy: Remove personal data from prompts; store outputs in course-approved system.</li> <li>Licensing: Ensure generated content complies with institutional policy; mark any external data sources.</li> </ul>"},{"location":"examples/faculty/industrial-design/quickstart/#additional-notes","title":"Additional Notes","text":"<ul> <li>Special requirement: Course requires proof-of-concept physical prototype by week 6\u2014LLM workflow must leave room for build time.</li> <li>Coordination ask: Request access to GPT-5/ChatGPT team workspace and clear guidance on storing prompt logs for accreditation.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/","title":"Simulation","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/industrial-design/simulation/#genai-sandbox-faculty-exploration-template-industrial-design-simulation","title":"GENAI Sandbox \u2013 Faculty Exploration Template (Industrial Design Simulation)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"examples/faculty/industrial-design/simulation/#sandbox-overview","title":"Sandbox Overview","text":"<p>\"This sandbox concept is your space to explore AI-enhanced teaching before classroom deployment. Share what you learn, keep materials CC-BY where possible, and flag integrity questions during the monthly pulse. The checklist below keeps governance light; use it as a reminder, not a barrier.\"</p> <ul> <li>[x] Transparency: I can explain any AI-generated material included here.</li> <li>[x] Student data &amp; privacy: Prompt logs scrubbed; stored in approved course workspace.</li> <li>[ ] Licensing: GPT-5 workspace terms under review; awaiting confirmation from coordination team.</li> <li>Notes / Exceptions: External material database referenced\u2014citation logged in Miro board.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#1-exploration-goal-snapshot","title":"1. Exploration Goal Snapshot","text":"<ul> <li>Goal (1\u20132 sentences): Enable teams to co-create structured design briefs with an LLM, freeing more studio time for prototyping while preserving human judgment.</li> <li>Intended audience: 20 third-year industrial design students (five teams of four).</li> <li>Why this matters now: Teams spend 8\u201310 hours drafting briefs before prototyping, compressing build time and limiting iteration cycles.</li> <li>Special requirements or constraints (accessibility, departmental needs, etc.): Accreditation requires storing design rationale; physical prototype due by week 6.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#2-workflow-experiment-log","title":"2. Workflow &amp; Experiment Log","text":"Step AI Assist Human Judgment Evidence / Notes 1 GPT-5 generates initial design brief based on prompt (user persona, environment, constraints) Teams review brief, highlight sections to keep/edit/remove Miro card showing prompt, AI output, student annotations 2 GPT-5 suggests material options and potential fabrication methods Teams vet suggestions against lab capabilities and budget Comparison table; rejected materials flagged with rationale 3 GPT-5 produces constraint checklist (ergonomics, durability, sustainability) Teams add missing constraints, reorganize priority levels Checklist layered in Miro with color-coded edits 4 Teams run quick plausibility check via Rhino LLM plugin (dimensions, tolerances) Instructor reviews flagged concerns, schedules lab consults Rhino screenshots appended with instructor comments 5 Teams move into physical prototyping sprint (foam mockups) referencing refined brief Instructor monitors build time vs. planned timeline Prototype photos + time tracking sheet uploaded 6 Post-sprint review: teams document LLM contributions vs. human adjustments Instructor consolidates insights for studio retrospective Contribution log stored in LMS; highlights on Miro <ul> <li>Iteration notes: LLM initially recommended carbon fiber despite budget constraints\u2014prompt adjusted to emphasize low-cost materials. Rhino plugin caught dimension mismatch; team resolved before build.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#3-outputs-artifacts","title":"3. Outputs &amp; Artifacts","text":"<ul> <li>Artifact 1 (link / location): Miro export containing prompts, annotated outputs, and constraint checklist (<code>examples/industrialdesign-sim-board.pdf</code>).</li> <li>Artifact 2 (optional): Contribution log spreadsheet summarizing accepted vs. rejected LLM suggestions.</li> <li>Supporting media or walkthrough: Prototype photo collage with callouts linking back to refined brief elements.</li> <li>Audience feedback captured (if any): Teams reported saving ~6 hours on brief creation; mentor noted clearer constraint documentation.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#4-reflection-check-in","title":"4. Reflection Check-In","text":"<ol> <li>What shifted during the sandbox run?</li> <li>Drafting time dropped from ~9 hours to 3 hours, allowing two additional prototyping iterations within the sprint.</li> <li>How did AI help or hinder your approach?</li> <li>Helped by structuring briefs and surfacing overlooked constraints; hindered when suggesting materials beyond lab capabilities.</li> <li>What will you keep, change, or try next?</li> <li>Keep LLM-assisted constraint checklists; change prompts to pre-filter by lab inventory; next, trial LLM-generated testing scenarios versus actual performance data.</li> </ol>"},{"location":"examples/faculty/industrial-design/simulation/#5-verification-snapshot","title":"5. Verification Snapshot","text":"Output / Decision How I verified it Confidence (low/med/high) GPT-5 design brief Cross-checked against user research notes; instructor validated scope coverage Medium Material suggestions Compared with lab inventory and supplier specs; removed non-compliant options High Constraint checklist Reviewed with accreditation rubric; ensured documentation stored in LMS High <ul> <li>Follow-up questions for coordination (policy, feasibility, other constraints): Clarify retention period for prompt logs; confirm process for sharing GPT-5 workspace across teams and finalizing licensing review.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#6-next-experiment-hooks","title":"6. Next Experiment Hooks","text":"<ul> <li>Next idea I want to explore: Pair LLM-generated test scenarios with real prototype data to assess feasibility.</li> <li>Support I could use (community feedback, resources, tooling): Examples from engineering department on constraint validation; guidance on centralizing prompt logs.</li> <li>Planned share-out (department meeting, sandbox cohort session, etc.): Present during industrial design brown-bag and sandbox orientation showcase.</li> </ul>"},{"location":"examples/faculty/industrial-design/simulation/#optional-persona-prompt-sidebar","title":"Optional Persona Prompt Sidebar","text":"<ul> <li>Starter prompts: \u201cDraft a design brief for a commuter accessory used in rainy climates\u2026\u201d</li> <li>Optimizer prompts: \u201cIdentify constraints a prototyping team might miss for this brief; prioritize them by risk.\u201d</li> </ul> <p>Need inspiration? Check the shared exemplars in <code>docs/examples/shared/</code> for workflow and verification samples.</p>"},{"location":"examples/faculty/physics-mcq/quickstart/","title":"Quickstart","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/physics-mcq/quickstart/#faculty-simulation-physics-assessment-persona-quickstart","title":"Faculty Simulation \u2013 Physics Assessment Persona Quickstart","text":""},{"location":"examples/faculty/physics-mcq/quickstart/#persona-snapshot","title":"Persona Snapshot","text":"<ul> <li>Department: Physics (Mechanics)</li> <li>Instructor Goal: Partner with an AI assistant to draft high-quality concept and quantitative multiple-choice questions (MCQs) with fair distractors for bi-weekly concept checks.</li> <li>Course Context: Introductory Mechanics I (SN1) with 36 students; flipped classroom model with bi-weekly concept checks.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#1-set-exploration-goal","title":"1. Set Exploration Goal","text":"<ul> <li>Challenge: Writing fresh MCQs with meaningful distractors takes hours and often reuses prior exam material.</li> <li>Prototype Goal: Build an AI + SME workflow that generates candidate questions, surfaces rationale, and allows quick validation before publishing quizzes.</li> <li>Audience: Primary instructor and course committee; students can receive some questions via LMS quizzes or practice sets.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#2-map-the-sandbox-run","title":"2. Map the Sandbox Run","text":"<ul> <li>Tools to Trial: GPT-5 (question generation, distractor suggestions), custom rubric checklist, Gradescope item bank for storage, Google Sheets tracker for QA.</li> <li>Workflow Snapshot Draft: Seed prompt with learning objective \u2192 AI drafts MCQ + rationale \u2192 SME review + edits \u2192 distractor fairness check \u2192 pilot in practice quiz \u2192 collect item stats.</li> <li>Rapid Test: Apply with faculty committee to two bi-weekly concept checks covering energy conservation in oscillations and Newton\u2019s laws with friction (student pilot optional).</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#3-experiment-capture-learnings","title":"3. Experiment &amp; Capture Learnings","text":"<ul> <li>Store prompts/outputs in shared drive with version control; include SME edit notes.</li> <li>Track metrics: Time spent per question, number of edits required, discrimination index from practice quiz analytics, student feedback on clarity.</li> <li>Risks: AI generating subtly incorrect physics statements, distractors that are either too easy or misleading, academic integrity if questions resemble public pools.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#4-prep-share-out-artifact","title":"4. Prep Share-Out Artifact","text":"<ul> <li>Deliverable: MCQ development sheet showing AI draft, SME revision annotations, distractor rationale matrix, and resulting question performance summary.</li> <li>Story: Learning objective \u2192 AI draft \u2192 SME critique \u2192 final item \u2192 pilot results \u2192 next steps.</li> <li>Evidence: Annotated question versions, QA checklist completion, item stats from Gradescope export.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#5-reflection-next-steps","title":"5. Reflection &amp; Next Steps","text":"<ul> <li>Questions: Did AI save drafting time without sacrificing precision? Were distractors fair and aligned with common misconceptions?</li> <li>Next Experiment Idea: Use AI to suggest follow-up open response questions based on MCQ performance gaps.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#6-safety-guardrails","title":"6. Safety Guardrails","text":"<ul> <li>Integrity: SMEs must fact-check every AI-generated statement and confirm units/values.</li> <li>Student data &amp; privacy: Remove any identifying info from item analytics; store in secured course drive.</li> <li>Licensing: Ensure AI prompt outputs are original; run plagiarism check before adding to item bank.</li> </ul>"},{"location":"examples/faculty/physics-mcq/quickstart/#additional-notes","title":"Additional Notes","text":"<ul> <li>Special requirement: Department course committee requires documentation of question provenance and revision history; sandbox focus is faculty-facing first, with optional student pilots once committee approves.</li> <li>Coordination ask: Need shared template for recording SME approvals and syncing with Gradescope item bank.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/","title":"Simulation","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/faculty/physics-mcq/simulation/#genai-sandbox-faculty-exploration-template-physics-mcq-simulation","title":"GENAI Sandbox \u2013 Faculty Exploration Template (Physics MCQ Simulation)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"examples/faculty/physics-mcq/simulation/#sandbox-overview","title":"Sandbox Overview","text":"<p>\"This sandbox concept is your space to explore AI-enhanced teaching before classroom deployment. Share what you learn, keep materials CC-BY where possible, and flag integrity questions during the monthly pulse. The checklist below keeps governance light; use it as a reminder, not a barrier.\"</p> <ul> <li>[x] Transparency: I can explain any AI-generated material included here.</li> <li>[x] Student data &amp; privacy: Item analytics anonymized; stored in secured course drive.</li> <li>[x] Licensing: AI-generated content checked for originality; final items tagged with provenance.</li> <li>Notes / Exceptions: Pending confirmation from assessment committee on long-term storage policy.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#1-exploration-goal-snapshot","title":"1. Exploration Goal Snapshot","text":"<ul> <li>Goal (1\u20132 sentences): Create a repeatable AI + SME workflow that generates accurate physics MCQs with fair distractors so bi-weekly concept checks stay fresh and high-quality.</li> <li>Intended audience: 36 students in PHYS 201 (Mechanics I); reviewed by lead instructor, two TAs, and course committee faculty.</li> <li>Why this matters now: Instructor spends ~6 hours/week drafting questions; item pool has become stale and leaks into student study forums.</li> <li>Special requirements or constraints (accessibility, departmental needs, etc.): Assessment committee requires provenance documentation; LMS demands WCAG-compliant math formatting; follow Bloom\u2019s taxonomy targets set in syllabus.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#2-workflow-experiment-log","title":"2. Workflow &amp; Experiment Log","text":"Step AI Assist Human Judgment Evidence / Notes 1 GPT-5 generates MCQ stem, answer, distractors based on prompt with learning objective and difficulty target Lead instructor reviews physics accuracy, units, and conceptual focus Stored in question development sheet (AI draft tab) 2 GPT-5 provides rationale for each distractor (misconception mapping) TAs evaluate fairness, flag ambiguous wording, adjust numeric values Rationale matrix annotated with SME comments 3 AI suggests alternative versions (numeric variants, conceptual twist) Instructor selects final version, edits distractors for clarity Version history captured in Google Sheets tracker 4 QA checklist runs: automated unit check, plagiarism scan, difficulty prediction SMEs sign off via initials once checklist passes Checklist stored with timestamp and reviewer initials 5 Question optionally piloted in Gradescope practice quiz; analytics exported (discrimination, p-value) if student run occurs Instructor/committee interprets stats, decides keep/revise/retire when pilot data available Analytics summary appended to development sheet 6 Finalized item added to secure item bank with provenance metadata Assessment committee notified via shared log Item bank entry includes AI prompt, reviewers, performance stats <ul> <li>Iteration notes: Initial AI output misapplied work-energy theorem; prompt now enforces \u201cmechanics units\u201d reminder. Distractor rationale helped highlight missing misconception about normal force direction, leading to new distractor.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#3-outputs-artifacts","title":"3. Outputs &amp; Artifacts","text":"<ul> <li>Artifact 1 (link / location): MCQ development sheet with AI drafts, SME annotations, and performance summary (<code>examples/physics-mcq-sim-sheet.pdf</code>).</li> <li>Artifact 2 (optional): QA checklist template completed for work-energy theorem question.</li> <li>Supporting media or walkthrough: 2-minute Loom highlighting workflow in Google Sheets + Gradescope analytics view.</li> <li>Audience feedback captured (if any): TAs reported question review time dropped from 20 to 8 minutes; faculty reviewers noted distractors felt \u201cfair but challenging,\u201d student pilot optional depending on sandbox scope.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#4-reflection-check-in","title":"4. Reflection Check-In","text":"<ol> <li>What shifted during the sandbox run?</li> <li>Drafting plus review time cut from ~6 hours to 2.5 hours during committee review; item discrimination estimated at 0.42 in limited student pilot.</li> <li>How did AI help or hinder your approach?</li> <li>Helped by surfacing misconception-based distractors quickly; hindered when algebra steps in rationale were sloppy\u2014required manual correction.</li> <li>What will you keep, change, or try next?</li> <li>Keep AI-assisted distractor rationale; change prompt to enforce symbolic accuracy; next, auto-generate brief solution explanations paired with practice feedback.</li> </ol>"},{"location":"examples/faculty/physics-mcq/simulation/#5-verification-snapshot","title":"5. Verification Snapshot","text":"Output / Decision How I verified it Confidence (low/med/high) AI-generated MCQ content Double-checked formulas, ran through secondary physics SME for work-energy theorem item Medium Distractor fairness Applied misconception checklist + reviewed student pilot feedback High Item analytics link Verified Gradescope export anonymized and stored with restricted access High <ul> <li>Follow-up questions for coordination (policy, feasibility, other constraints): Need official workflow for assessment committee sign-off; confirm retention period for AI prompts in item bank.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#6-next-experiment-hooks","title":"6. Next Experiment Hooks","text":"<ul> <li>Next idea I want to explore: Use AI to propose targeted remedial questions for students who miss specific distractors.</li> <li>Support I could use (community feedback, resources, tooling): Input from math department on symbolic accuracy prompts; guidance on automating QA checklist via scripts.</li> <li>Planned share-out (department meeting, sandbox cohort session, etc.): Present at physics assessment working group and sandbox orientation.</li> </ul>"},{"location":"examples/faculty/physics-mcq/simulation/#optional-persona-prompt-sidebar","title":"Optional Persona Prompt Sidebar","text":"<ul> <li>Starter prompts: \u201cGenerate a concept-level MCQ on work-energy theorem that tests understanding of energy transfer in damped oscillations; include common misconceptions in distractors.\u201d</li> <li>Optimizer prompts: \u201cFor the correct answer, provide a student-friendly rationale and note which misconception each distractor targets.\u201d</li> </ul> <p>Need inspiration? Check the shared exemplars in <code>docs/examples/shared/</code> for workflow and verification samples.</p>"},{"location":"examples/shared/verification-log-example/","title":"Verification Log","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/shared/verification-log-example/#verification-log-example-student-space-project","title":"Verification Log Example \u2013 Student SPACE Project","text":"Output / Decision How I checked it Confidence Study guide summary Compared with class notes, confirmed citations, asked mentor to spot-check one topic High Practice problem hints Ran hints through solver, verified answers manually for two variants Medium Resource list Confirmed links active, tagged AI-generated blurbs, added human-authored alternatives High <p>Questions for mentors: Need advice on designing a quick peer validation loop for future iterations.</p>"},{"location":"examples/shared/workflow-snapshot-example/","title":"Workflow Snapshot","text":"<p>Back to Faculty Sandbox | Resources: resources.md</p>"},{"location":"examples/shared/workflow-snapshot-example/#workflow-snapshot-example-faculty-prototype","title":"Workflow Snapshot Example \u2013 Faculty Prototype","text":"Step AI Assist Human Judgment Evidence / Notes Draft quiz questions GPT-generated question bank seeded with course outline Instructor filters for alignment with learning outcomes, edits phrasing Saved quiz in LMS with instructor annotations Provide rapid feedback AI tool scores student submissions against rubric Instructor reviews edge cases, records voice feedback for flagged answers Screenshot of AI dashboard + summary of manual overrides Create reflection prompt GPT drafts post-quiz reflection question Instructor tweaks tone to match course culture Final prompt shared in discussion forum <p>Iteration notes: Switched from generic quiz model to subject-specific prompt after early mismatch; captured final prompt in appendix for reuse.</p>"},{"location":"guides/faculty-sandbox-template/","title":"Faculty Template","text":"<p>Back to Faculty Sandbox | Quickstart: GENAI Sandbox Outline | Student Kit: SPACE Sandbox</p>"},{"location":"guides/faculty-sandbox-template/#genai-sandbox-faculty-exploration-template-draft","title":"GENAI Sandbox \u2013 Faculty Exploration Template (Draft)","text":"<p>Last updated: 2025-09-21 \u00b7 Use with the Quickstart in <code>docs/quickstart-outline.md</code></p>"},{"location":"guides/faculty-sandbox-template/#sandbox-overview","title":"Sandbox Overview","text":"<p>\"This sandbox concept is your space to explore AI-enhanced teaching before classroom deployment. Share what you learn, keep materials CC-BY where possible, and flag accessibility or integrity questions during the monthly pulse. The checklist below keeps governance light; use it as a reminder, not a barrier.\"</p> <ul> <li>[ ] Transparency: I can explain any AI-generated material included here.</li> <li>[ ] Student data &amp; privacy: I protected personal information and followed institutional data-use rules.</li> <li>[ ] Licensing: Assets are CC-BY or note exceptions below.</li> <li>Notes / Exceptions:</li> </ul>"},{"location":"guides/faculty-sandbox-template/#1-exploration-goal-snapshot","title":"1. Exploration Goal Snapshot","text":"<ul> <li>Goal (1\u20132 sentences):</li> <li>Intended audience:</li> <li>Why this matters now:</li> <li>Special requirements or constraints (accessibility, departmental needs, etc.):</li> </ul>"},{"location":"guides/faculty-sandbox-template/#2-workflow-experiment-log","title":"2. Workflow &amp; Experiment Log","text":"Step AI Assist Human Judgment Evidence / Notes 1 2 3 4 5 6 <ul> <li>Iteration notes (adjustments, surprises, prompts worth saving):</li> </ul>"},{"location":"guides/faculty-sandbox-template/#3-outputs-artifacts","title":"3. Outputs &amp; Artifacts","text":"<ul> <li>Artifact 1 (link / location):</li> <li>Artifact 2 (optional):</li> <li>Supporting media or walkthrough:</li> <li>Audience feedback captured (if any):</li> </ul>"},{"location":"guides/faculty-sandbox-template/#4-reflection-check-in","title":"4. Reflection Check-In","text":"<ol> <li>What shifted during the sandbox run?    -</li> <li>How did AI help or hinder your approach?    -</li> <li>What will you keep, change, or try next?    -</li> </ol>"},{"location":"guides/faculty-sandbox-template/#5-verification-snapshot","title":"5. Verification Snapshot","text":"Output / Decision How I verified it Confidence (low/med/high) <ul> <li>Follow-up questions for coordination (policy, feasibility, other constraints):</li> </ul>"},{"location":"guides/faculty-sandbox-template/#6-next-experiment-hooks","title":"6. Next Experiment Hooks","text":"<ul> <li>Next idea I want to explore:</li> <li>Support I could use (community feedback, resources, tooling):</li> <li>Planned share-out (department meeting, sandbox cohort session, etc.):</li> </ul>"},{"location":"guides/faculty-sandbox-template/#optional-persona-prompt-sidebar","title":"Optional Persona Prompt Sidebar","text":"<ul> <li>Starter prompts: \u201cWhat if AI handled \u2026?\u201d, \u201cWhere did students struggle last term?\u201d, \u201cWhich feedback loop takes me the longest?\u201d</li> <li>Optimizer prompts: \u201cHow can I validate this output faster?\u201d, \u201cWhat exemplar would convince leadership to scale this?\u201d</li> </ul> <p>Need inspiration? Check the shared exemplars in <code>docs/examples/shared/</code> for workflow and verification samples.</p>"},{"location":"guides/space-student-guide/","title":"SPACE Student Guide","text":"<p>Back to Faculty Sandbox | Visit SPACE Sandbox | Foundational Quickstart: SPACE quickstart</p>"},{"location":"guides/space-student-guide/#space-self-directed-project-guide-draft","title":"SPACE Self-Directed Project Guide (Draft)","text":"<p>Last updated: 2025-09-21 \u00b7 Align with Quickstart <code>../space/foundational/quickstart.md</code></p>"},{"location":"guides/space-student-guide/#sandbox-spirit-guardrails","title":"Sandbox Spirit &amp; Guardrails","text":"<p>\"SPACE projects are exploration-first. Use this guide to document what you try, what you learn, and how you\u2019ll share it. Keep your experiments transparent, cite sources, and note how you checked the AI\u2019s work. If something feels off, reach out during office hours or via the forum.\" </p> <ul> <li>[ ] I can explain how AI contributed to each artifact.</li> <li>[ ] I credited any reused assets (CC-BY or otherwise noted).</li> <li>[ ] I protected any sensitive data including my own.</li> <li>Notes / Questions:</li> </ul>"},{"location":"guides/space-student-guide/#1-project-focus","title":"1. Project Focus","text":"<ul> <li>Challenge I\u2019m exploring (1\u20132 sentences):</li> <li>Intended beneficiaries (me, peers, club, course):</li> <li>SPACE certificate credit, if applicable (e.g., foundational knowledge, capstone):</li> <li>Success looks like:</li> </ul>"},{"location":"guides/space-student-guide/#2-experiment-tracker","title":"2. Experiment Tracker","text":"Attempt Tool / Prompt What I tested What happened Next tweak 1 2 3 4 <ul> <li>Prompt snippets or settings I want to remember:</li> </ul>"},{"location":"guides/space-student-guide/#3-workflow-snapshot-when-process-stabilizes","title":"3. Workflow Snapshot (when process stabilizes)","text":"Step AI Assist My Judgment Proof / Evidence 1 2 3"},{"location":"guides/space-student-guide/#4-showcase-artifact-plan","title":"4. Showcase Artifact Plan","text":"<ul> <li>Artifact format (guide, video, demo, etc.):</li> <li>Key insights or stories to highlight:</li> <li>How I\u2019ll share it (SPACE website, challenge demo, SPACE end-of-year showcase):</li> <li>Link, if applicable:</li> </ul>"},{"location":"guides/space-student-guide/#5-reflection-loop","title":"5. Reflection Loop","text":"<ol> <li>Biggest thing that changed during this process compared to my initial goals:</li> <li>AI strengths &amp; limitations I noticed:</li> <li>What I would do next if I had another sprint:</li> </ol>"},{"location":"guides/space-student-guide/#6-integrity-touchpoints","title":"6. Integrity Touchpoints","text":"Output / Decision How I checked it Confidence <ul> <li>Questions for mentors:</li> </ul>"},{"location":"guides/space-student-guide/#7-future-routes","title":"7. Future Routes","text":"<ul> <li>Next experiment or collaboration idea:</li> <li>Skills or resources I want to grow:</li> <li>How I will collect feedback (if needed):</li> </ul>"},{"location":"guides/space-student-guide/#optional-prompt-boosters","title":"Optional Prompt Boosters","text":"<ul> <li>Starter: \u201cWhat part of this project could be lighter if AI helped?\u201d / \u201cHow would a friend use this artifact?\u201d</li> <li>Optimizer: \u201cWhat evidence will convince others this workflow is trustworthy?\u201d / \u201cHow can I stress-test this with limited time?\u201d</li> </ul> <p>Drop finished artifacts and lessons learned into the SPACE hub. Exemplars will be collected in <code>docs/examples/shared/</code> as they emerge.</p>"},{"location":"guides/template-spine-outline/","title":"Template Spine Outline","text":"<p>Back to Faculty Sandbox | Resources: resources.md | Orientation: orientation-outline.md</p>"},{"location":"guides/template-spine-outline/#streamlined-template-spine-shared-elements-draft","title":"Streamlined Template Spine \u2013 Shared Elements (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"guides/template-spine-outline/#shared-governance-preface-120-words","title":"Shared Governance Preface (\u2264120 words)","text":"<ul> <li>Welcome to the GENAI Sandbox: focus on exploration, iteration, and storytelling.</li> <li>Reminder of CC-BY sharing, transparency, and accessibility commitments.</li> <li>Mention that integrity checks live inside the template; governance team available via monthly pulse if questions arise.</li> </ul>"},{"location":"guides/template-spine-outline/#section-order-required-fields","title":"Section Order &amp; Required Fields","text":"<ol> <li>Exploration Goal Snapshot</li> <li>Goal statement (1\u20132 sentences)</li> <li>Audience focus (students, colleagues, self)</li> <li>Prototype window dates</li> <li>Workflow &amp; Experiment Log</li> <li>Table with columns: Step | AI Assist | Human Judgment | Evidence/Notes</li> <li>Space for up to 6 steps; encourage iteration notes beneath table</li> <li>Outputs &amp; Artifacts</li> <li>Bullet slots for artifacts generated (link or brief description)</li> <li>Optional media reference (slide deck, video, SPACE post)</li> <li>Reflection Check-In</li> <li>Q1: What shifted during this sandbox run?</li> <li>Q2: How did AI help or hinder your approach?</li> <li>Q3: What will you keep, change, or try next?</li> <li>Safety Guardrails &amp; Verification</li> <li>Checklist (integrity, transparency, accessibility) with yes/no + notes</li> <li>Mini-table for verification evidence (Output | How verified | Confidence)</li> <li>Next Experiment Hooks</li> <li>Planned follow-up exploration (1\u20132 bullets)</li> <li>Support needed from community or coordination team</li> </ol>"},{"location":"guides/template-spine-outline/#optional-modules-add-on","title":"Optional Modules (Add-on)","text":"<ul> <li>Persona-specific prompt sidebar (faculty vs. student self-directed)</li> <li>Department terminology swaps (fields to rename)</li> <li>Case-study capsule callout (for coordination team use)</li> </ul>"},{"location":"guides/template-spine-outline/#cross-template-guidelines","title":"Cross-Template Guidelines","text":"<ul> <li>Keep instructions inline and concise; link to quickstart for full context.</li> <li>Use examples in <code>docs/examples/shared/</code> for workflow table and verification entries.</li> <li>Encourage annotations/screenshots rather than long-form prose.</li> </ul>"},{"location":"orientation/orientation-outline/","title":"Orientation","text":"<p>Quick Links: Faculty Sandbox | SPACE Sandbox | Resources Hub | Use Cases</p>"},{"location":"orientation/orientation-outline/#genai-sandbox-orientation-faculty-simulation-showcase-draft","title":"GENAI Sandbox Orientation \u2013 Faculty Simulation Showcase (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"orientation/orientation-outline/#1-welcome-framing-5-min","title":"1. Welcome &amp; Framing (5 min)","text":"<ul> <li>Highlight sandbox goals: explore, document, share.</li> <li>Introduce streamlined templates + quickstart (reference <code>docs/resources.md</code>).</li> <li>Present faculty use case menu to inspire selection (<code>docs/use-cases/faculty-sandbox-use-cases.md</code>).</li> </ul>"},{"location":"orientation/orientation-outline/#2-simulation-highlights-15-min","title":"2. Simulation Highlights (15 min)","text":"<ul> <li>Humanities: AI summaries + student critique (show workflow snapshot and reflection gains).</li> <li>Industrial Design: GPT-5 co-designer workflow (constraint checklist with lab readiness).</li> <li>Physics MCQ: AI + SME question design (QA checklist and analytics loop).</li> <li>CS Code Review: Low-stakes Claude/ChatGPT assist (before/after code diff and turnaround data).</li> <li>Mention archived extras (Applied Arts, lab prep) as reference.</li> </ul>"},{"location":"orientation/orientation-outline/#3-hands-on-walkthrough-10-min","title":"3. Hands-On Walkthrough (10 min)","text":"<ul> <li>Quickstart demo: choose a persona, fill exploration goal, map workflow.</li> <li>Show how to capture outputs in faculty template (Goal \u2192 Workflow \u2192 Evidence \u2192 Reflection \u2192 Guardrails).</li> <li>Invite participants to mark interest in specific use cases or propose new ones.</li> </ul>"},{"location":"orientation/orientation-outline/#4-resource-review-5-min","title":"4. Resource Review (5 min)","text":"<ul> <li>Point to resource hub and templates (<code>docs/guides/</code>).</li> <li>Share exemplar files from the Faculty simulations library (workflow, verification, code review packets) plus SPACE student examples (foundational \u00b7 AI Making).</li> <li>Explain archive access for legacy templates (<code>docs/archive/</code>).</li> </ul>"},{"location":"orientation/orientation-outline/#5-next-steps-support-5-min","title":"5. Next Steps &amp; Support (5 min)","text":"<ul> <li>Confirm monthly pulse check and Oct 22 workshop.</li> <li>Review guardrail reminders (transparency, privacy, licensing, safety sign-offs) using the checklist in <code>docs/guides/faculty-sandbox-template.md</code>.</li> <li>Outline how to log new use cases/feedback (coordination contact, tracker update) using <code>docs/use-cases/faculty-sandbox-use-cases.md</code> and monthly pulse).</li> </ul>"},{"location":"orientation/orientation-outline/#appendix-assets","title":"Appendix Assets","text":"<ul> <li>Slide deck placeholders linking to sample artifacts (to be built).</li> <li>Orientation demo files (PDF exports, Loom links) \u2013 pull from <code>docs/examples/faculty/</code> and <code>space/</code> once finalized.</li> </ul>"},{"location":"orientation/orientation-outline/#demo-inserts","title":"Demo Inserts","text":"<ul> <li>AI Making Challenge: Showcase data visualization simulation (<code>space/ai-making-challenge/examples/ai-making-sim-data-viz.md</code>) with Prompt &amp; Validate loop (prompt log, accessibility check, intervention).</li> <li>Media art duo example as optional alternate.</li> </ul>"},{"location":"space/","title":"SPACE Sandbox","text":"<p>Quick Links: Foundational Track | AI Making Challenge | Faculty Sandbox | Sitemap</p> <p>This portal gathers all student-facing sandbox resources JT can run alongside the faculty program.</p>"},{"location":"space/#foundational-knowledge-track","title":"Foundational Knowledge Track","text":"<ul> <li>Quickstart: foundational/quickstart.md</li> <li>Template: foundational/template.md</li> <li>Example \u2013 Nursing dosage study guide: quickstart | simulation</li> <li>Notes &amp; tasks: Internal coordination document</li> </ul>"},{"location":"space/#ai-making-challenge-2025","title":"AI Making Challenge 2025","text":"<ul> <li>Quickstart: ai-making-challenge/quickstart.md</li> <li>Template: ai-making-challenge/template.md</li> <li>Examples: media art duo | data viz solo</li> <li>Coordinator notes: Internal coordination document</li> <li>Official links: Devpost \u00b7 Discord</li> </ul>"},{"location":"space/#guidance-integrity","title":"Guidance &amp; Integrity","text":"<ul> <li>Use the SPACE template reflection prompts to document how AI supported (or hindered) your work.</li> <li>Keep prompts, validations, and interventions transparent; anonymize personal data before sharing.</li> <li>Check licensing/attribution for any AI-generated media before publishing.</li> </ul>"},{"location":"space/#stay-in-sync","title":"Stay in Sync","text":"<ul> <li>For updates or questions, annotate the relevant notes files or raise them during SPACE coordination meetings.</li> <li>Faculty Sandbox resources live at docs/index.md for shared context.</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/","title":"Quickstart","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/ai-making-challenge/quickstart/#ai-making-challenge-2025-quickstart-prompt-validate","title":"AI Making Challenge 2025 Quickstart (Prompt &amp; Validate)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/ai-making-challenge/quickstart/#1-clarify-your-challenge-idea","title":"1. Clarify Your Challenge Idea","text":"<ul> <li>Choose a project type (story, visualization, app, music, etc.) and define your goal in one sentence.</li> <li>Note whether you\u2019re working solo or with a teammate (max 2 people) and how you\u2019ll collaborate.</li> <li>List any inspiration or constraints (time, skills, licensing, accessibility).</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/#2-map-your-prompt-validate-loop","title":"2. Map Your Prompt &amp; Validate Loop","text":"<ul> <li>Identify the AI tool(s) you\u2019ll use (Claude, ChatGPT, Runway, etc.) and what each will help you produce.</li> <li>Sketch a loop: Prompt \u2192 AI Output \u2192 Validate (check, critique) \u2192 Intervene (edit, combine, add human work).</li> <li>Decide how you\u2019ll track each iteration (shared doc, spreadsheet, version control).</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/#3-plan-your-validation-ethics-checks","title":"3. Plan Your Validation &amp; Ethics Checks","text":"<ul> <li>Set criteria for success: accuracy, originality, audience fit, ethical considerations.</li> <li>Outline how you\u2019ll check data sources, bias, licensing, and transparency.</li> <li>Note any experts/mentors you\u2019ll consult for feedback.</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/#4-build-document-iterations","title":"4. Build &amp; Document Iterations","text":"<ul> <li>Run multiple prompt cycles; save prompts, outputs, decisions, and human contributions.</li> <li>Keep screenshots, code snippets, sound/video drafts, or storyboard frames for your submission package.</li> <li>Highlight where you intervened to shape the project (edits, combinations, new elements).</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/#5-assemble-artifact-presentation","title":"5. Assemble Artifact &amp; Presentation","text":"<ul> <li>Curate the final project artifact (ready-to-share prototype) and supporting files.</li> <li>Prepare a presentation deck or video that tells the story: goal \u2192 prompt/validate journey \u2192 human contribution \u2192 final outcome \u2192 lessons learned.</li> <li>Include reflection on ethics, bias, ownership, and future improvements.</li> </ul>"},{"location":"space/ai-making-challenge/quickstart/#6-reflect-submit","title":"6. Reflect &amp; Submit","text":"<ul> <li>Answer challenge guiding questions (goals, AI\u2019s role, data origins, bias, ownership, implications).</li> <li>Make sure all requirements from Devpost/SPACE are met: artifact, reflection, documentation, licensing notes.</li> <li>Submit by May 9, 2025 and prepare for the showcase.</li> </ul> <p>Use the challenge template (<code>template.md</code>) to capture all your prompts, validations, interventions, and reflections in one place.</p>"},{"location":"space/ai-making-challenge/template/","title":"Template","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/ai-making-challenge/template/#ai-making-challenge-2025-template-draft","title":"AI Making Challenge 2025 Template (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/ai-making-challenge/template/#project-snapshot","title":"Project Snapshot","text":"<p>\"Our AI Making Challenge project captures how we prompt, validate, and intervene to create something uniquely ours.\"</p> <ul> <li>Team members:</li> <li>Project title:</li> <li>Project type (app, story, visualization, etc.):</li> <li>Links (Devpost draft, repo, media):</li> <li>SPACE goal (6-credit certificate / capstone option):</li> </ul>"},{"location":"space/ai-making-challenge/template/#1-challenge-focus","title":"1. Challenge Focus","text":"<ul> <li>What problem or idea are we exploring?</li> <li>Who is the audience or user?</li> <li>Why does this project matter to us?</li> </ul>"},{"location":"space/ai-making-challenge/template/#2-prompt-validate-loop-log","title":"2. Prompt &amp; Validate Loop Log","text":"Iteration Prompt / Input AI Output Summary Validation / Checks Human Intervention 1 2 3 <ul> <li>Additional notes (bias, surprises, tool limits):</li> </ul>"},{"location":"space/ai-making-challenge/template/#3-artifact-build-assets","title":"3. Artifact Build &amp; Assets","text":"<ul> <li>Key components (files, scenes, tracks, code modules):</li> <li>Human-created elements:</li> <li>AI-assisted elements:</li> <li>Evidence of intervention (screenshots, diffs, edit notes):</li> </ul>"},{"location":"space/ai-making-challenge/template/#4-ethics-bias-ownership","title":"4. Ethics, Bias &amp; Ownership","text":"<ul> <li>Data sources / training concerns:</li> <li>Biases encountered and how we addressed them:</li> <li>Licensing / attribution details:</li> <li>How we ensure transparency for viewers/users:</li> </ul>"},{"location":"space/ai-making-challenge/template/#5-reflection-learning","title":"5. Reflection &amp; Learning","text":"<ol> <li>What did we learn about AI\u2019s capabilities and limits during this project?</li> <li>How did our own expertise shape the final result?</li> <li>When was AI helpful vs. problematic, and why?</li> <li>What would we do next if we had more time?</li> </ol>"},{"location":"space/ai-making-challenge/template/#6-submission-checklist","title":"6. Submission Checklist","text":"<ul> <li>[ ] Artifact files prepared and linked.</li> <li>[ ] Prompt &amp; Validate log complete.</li> <li>[ ] Reflection ready for Devpost + SPACE submission.</li> <li>[ ] Licensing/attribution included.</li> <li>[ ] Showcase presentation deck/video drafted.</li> </ul> <p>Attach any supporting documents (e.g., code repo README, storyboard, user testing notes) when you submit to Devpost and SPACE.</p>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/","title":"Data Viz Example","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#ai-making-challenge-simulation-data-visualization-solo-project","title":"AI Making Challenge Simulation \u2013 Data Visualization Solo Project","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#project-snapshot","title":"Project Snapshot","text":"<ul> <li>Participant: Amina (Science \u2013 Environmental Studies)</li> <li>Title: \"City Air: Prompted Patterns\"</li> <li>Project Type: Interactive data visualization (web app)</li> <li>Links: (placeholder repo + hosted demo)</li> <li>SPACE Goal: Foundational Knowledge (science communication focus)</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#prompt-validate-log","title":"Prompt &amp; Validate Log","text":"Iteration Prompt / Input AI Output Summary Validation / Checks Human Intervention 1 Claude: \"Suggest datasets and visualization styles for Montreal air quality\" Proposed open data + radial charts Verified dataset availability/licensing; radial chart not accessible Chose bar/line combo; curated dataset manually 2 ChatGPT: \"Draft React component for AQI chart with tooltips\" Produced initial code with dummy data Ran ESLint, noticed missing accessibility props Amina added ARIA labels, swapped to D3 for customization 3 Claude: \"Generate narrative captions explaining AQI spikes\" Provided general explanation Cross-checked with meteorological events; some inaccuracies Rewrote captions referencing news sources and personal commentary 4 ChatGPT: \"Suggest validation plan for data pipeline\" Listed tests for data integrity Confirmed steps against actual pipeline Implemented tests + logged results in README"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#artifact-build","title":"Artifact Build","text":"<ul> <li>Human-made: Dataset selection/cleanup, D3 customization, narrative copy, UI styling.</li> <li>AI-assisted: Dataset brainstorming, starter code snippets, initial captions, validation checklist.</li> <li>Evidence: Git commits, prompt logs, accessibility audit screenshots.</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#ethics-bias-ownership","title":"Ethics, Bias &amp; Ownership","text":"<ul> <li>Data licensed under open government (proper attribution in app footer).</li> <li>Discusses bias in sensor placement across neighborhoods.</li> <li>AI prompts documented; final narrative authored by Amina.</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-data-viz/#reflection-highlights","title":"Reflection Highlights","text":"<ul> <li>AI sped up prototyping but human interpretation grounded the story.</li> <li>Learned to check AI code for accessibility and context accuracy.</li> <li>Next step: add mobile view + share on Devpost, gather feedback via Discord.</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/","title":"Media Art Example","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#ai-making-challenge-simulation-media-art-duo","title":"AI Making Challenge Simulation \u2013 Media Art Duo","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#project-snapshot","title":"Project Snapshot","text":"<ul> <li>Team: Maya (Graphic Design) &amp; Leo (Music)</li> <li>Title: \"Echoes of the Metro\"</li> <li>Project Type: Mixed-media video (AI-assisted visuals + original soundtrack)</li> <li>Links: (placeholder)</li> <li>SPACE Goal: Foundational Knowledge (creative tech focus)</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#iteration-log-prompt-validate","title":"Iteration Log (Prompt &amp; Validate)","text":"Iteration Prompt / Input AI Output Summary Validation / Checks Human Intervention 1 Claude prompt: \"Generate storyboard frames of Montreal metro at night in watercolor style\" Gave moody frames but inconsistent lighting Checked for licensing &amp; realism; noted mismatched station signage Maya re-drew key frames in Procreate, kept color palette 2 ChatGPT prompt: \"Suggest ambient sound layers for late-night metro ride\" List of foley elements + minor chord progression Evaluated against field recordings; some sounds unrealistic Leo recorded actual metro sounds, composed synth pad around suggested chord progression 3 Claude prompt: \"Write narration exploring AI bias in transit design\" Script leaned generic Validated against research on accessibility bias Duo rewrote sections highlighting Montreal context and personal reflections"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#artifact-build","title":"Artifact Build","text":"<ul> <li>Human-made: Hand-drawn frames, live-recorded audio, narration.</li> <li>AI-assisted: Storyboard drafts, sound-layer ideas, initial script.</li> <li>Proof: Miro board with prompt logs, Procreate layers, audio DAW screenshots.</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#ethics-ownership","title":"Ethics &amp; Ownership","text":"<ul> <li>AI visuals heavily edited; final art credited to team.</li> <li>Soundscape uses original field recordings; no unlicensed assets.</li> <li>Reflection addresses bias in AI urban planning imagery.</li> </ul>"},{"location":"space/ai-making-challenge/examples/ai-making-sim-media-art/#reflection-highlights","title":"Reflection Highlights","text":"<ul> <li>AI sped up brainstorming but human editing defined the style.</li> <li>Learned to question AI depictions of public spaces and representation.</li> <li>Next step: release zine documenting process + host Discord Q&amp;A.</li> </ul>"},{"location":"space/foundational/quickstart/","title":"Quickstart","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/foundational/quickstart/#space-foundational-project-quickstart-draft","title":"SPACE Foundational Project Quickstart (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/foundational/quickstart/#1-choose-your-focus","title":"1. Choose Your Focus","text":"<ul> <li>Pick a question or theme from the SPACE Foundational Knowledge certificate (e.g., \"How can AI support inclusive study guides?\").</li> <li>Decide who benefits (you, classmates, club, community) and what success looks like after one exploration sprint.</li> </ul>"},{"location":"space/foundational/quickstart/#2-map-your-sandbox-plan","title":"2. Map Your Sandbox Plan","text":"<ul> <li>List up to two AI tools you will test (Claude, ChatGPT, Perplexity, etc.) and what you expect them to do for you.</li> <li>Sketch a simple workflow table: Step \u2192 AI assist \u2192 Your judgment \u2192 Evidence you will save.</li> <li>Note any constraints (time, privacy, licensing, accessibility) before you start.</li> </ul>"},{"location":"space/foundational/quickstart/#3-run-experiments-capture-notes","title":"3. Run Experiments &amp; Capture Notes","text":"<ul> <li>Try your workflow in short bursts; save prompts, outputs, and reactions in a notebook or digital doc.</li> <li>Record what worked, what failed, and what you changed between attempts.</li> <li>Highlight moments where your own knowledge added value or corrected the AI.</li> </ul>"},{"location":"space/foundational/quickstart/#4-build-your-space-artifact","title":"4. Build Your SPACE Artifact","text":"<ul> <li>Pick a format that fits Foundational Knowledge submissions (slide deck, blog-style write-up, audio/video reflection, annotated resource guide).</li> <li>Show the story: your goal \u2192 experiments \u2192 what you made \u2192 what you learned.</li> <li>Include at least one example (screenshot, paragraph, audio clip) that shows AI + your contribution together.</li> </ul>"},{"location":"space/foundational/quickstart/#5-reflect-plan-next-steps","title":"5. Reflect &amp; Plan Next Steps","text":"<ul> <li>Answer the three prompts: What changed because of this project? How did AI help or hinder you? What will you do next?</li> <li>List any new questions or skills you want to explore in future SPACE work.</li> <li>Share feedback you need from mentors or peers.</li> </ul>"},{"location":"space/foundational/quickstart/#6-safety-integrity-reminders","title":"6. Safety &amp; Integrity Reminders","text":"<ul> <li>Keep your work transparent: tag where AI helped and how you verified it.</li> <li>Protect personal or confidential data when sharing prompts or outputs.</li> <li>Confirm licenses/terms before using AI-generated media; add attribution if required.</li> </ul> <p>Use this quickstart with the SPACE student template (<code>template.md</code>) to keep everything organized for submission.</p>"},{"location":"space/foundational/template/","title":"Template","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/foundational/template/#space-foundational-project-template-draft","title":"SPACE Foundational Project Template (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/foundational/template/#sandbox-snapshot","title":"Sandbox Snapshot","text":"<p>\"This SPACE foundational project is my playground to test AI support while staying true to my own thinking. I\u2019ll track how AI helps, where I step in, and what I can share with the SPACE community.\"</p> <ul> <li>[ ] I can explain how AI contributed to my work.</li> <li>[ ] I respected privacy (my data, peers, sources) and noted any sensitive content.</li> <li>[ ] I credited or licensed any AI-generated assets that I reused.</li> <li>Notes / Questions:</li> </ul>"},{"location":"space/foundational/template/#1-project-focus","title":"1. Project Focus","text":"<ul> <li>Exploration question or theme:</li> <li>Who benefits from this project (self, course, club, wider community):</li> <li>Time window for this sprint (start \u2192 target finish):</li> <li>What success looks like for this iteration:</li> </ul>"},{"location":"space/foundational/template/#2-experiment-log","title":"2. Experiment Log","text":"Attempt Tool / Prompt What I tried What happened What I changed next 1 2 3 <ul> <li>Prompts, settings, or resources I want to remember:</li> </ul>"},{"location":"space/foundational/template/#3-workflow-snapshot-after-refining","title":"3. Workflow Snapshot (after refining)","text":"Step AI Assist My Judgment Proof / Evidence 1 2 3"},{"location":"space/foundational/template/#4-artifact-story","title":"4. Artifact &amp; Story","text":"<ul> <li>Artifact format (deck, write-up, video, etc.):</li> <li>Key pieces I\u2019ll showcase (link or location):</li> <li>How the artifact demonstrates AI + my contribution:</li> <li>How I plan to share it (SPACE website, cohort meetup, other):</li> </ul>"},{"location":"space/foundational/template/#5-reflection-prompts","title":"5. Reflection Prompts","text":"<ol> <li>What changed because of this exploration compared to where I started?</li> <li>How did AI help me, and where did I need to step in or correct it?</li> <li>What will I keep, change, or try next time?</li> </ol>"},{"location":"space/foundational/template/#6-integrity-verification","title":"6. Integrity &amp; Verification","text":"Output / Decision How I checked it Confidence (low/med/high) <ul> <li>Questions for SPACE mentors or coordinators:</li> </ul>"},{"location":"space/foundational/template/#7-next-steps","title":"7. Next Steps","text":"<ul> <li>Next experiment or extension idea:</li> <li>Skills/resources I want to build:</li> <li>Who I\u2019ll ask for feedback (peer, mentor, instructor):</li> </ul>"},{"location":"space/foundational/template/#prompt-boosters-optional","title":"Prompt Boosters (Optional)","text":"<ul> <li>Starter: \u201cWhat part of this project would be easier if AI helped with research or drafting?\u201d</li> <li>Optimizer: \u201cHow can I show my own voice/skills alongside AI support so the SPACE community sees my growth?\u201d</li> </ul> <p>Submit this template with your artifact when you\u2019re ready for SPACE feedback or certificate review.</p>"},{"location":"space/foundational/examples/nursing-study-guide/quickstart/","title":"Quickstart","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/foundational/examples/nursing-study-guide/quickstart/#space-student-simulation-nursing-persona-quickstart","title":"SPACE Student Simulation \u2013 Nursing Persona Quickstart","text":""},{"location":"space/foundational/examples/nursing-study-guide/quickstart/#persona-snapshot","title":"Persona Snapshot","text":"<ul> <li>Program: Nursing</li> <li>Project Goal: Create an AI-assisted study guide that helps first-year nursing students practice medication dosage calculations safely.</li> <li>Certificate Track: SPACE Foundational Knowledge (Science &amp; Health focus).</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/quickstart/#quickstart-highlights","title":"Quickstart Highlights","text":"<ol> <li>Focus: Explore how AI can generate practice dosage problems while I verify accuracy and build confidence.</li> <li>Plan: Use Claude to draft practice questions, ChatGPT to suggest checking steps; track workflow (AI suggestion \u2192 my verification \u2192 final study card).</li> <li>Experiment Notes: Log prompts, highlight when AI output is wrong or missing context, note how I corrected it.</li> <li>Artifact: Slide deck with sample practice cards, verification notes, and tips for classmates.</li> <li>Reflection Prompts: What changed in my understanding? How did AI help/hinder safety? What next (perhaps integrate with simulation lab prep)?</li> <li>Guardrails: Protect patient data (use fictional cases), cite AI assistance, confirm calculations manually or with instructor-approved tools.</li> </ol>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/","title":"Simulation","text":"<p>Back to SPACE Sandbox | Visit Faculty Sandbox</p>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#space-foundational-project-template-nursing-simulation","title":"SPACE Foundational Project Template \u2013 Nursing Simulation","text":"<p>Last updated: 2025-09-21</p>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#sandbox-snapshot","title":"Sandbox Snapshot","text":"<p>\"This SPACE foundational project lets me test AI support for nursing dosage practice while ensuring patient safety remains my responsibility.\"</p> <ul> <li>[x] I can explain how AI contributed to my work.</li> <li>[x] I respected privacy (all scenarios are fictional, no patient data).</li> <li>[x] I credited/checked AI-generated practice questions.</li> <li>Notes / Questions: Confirm with faculty mentor how to share deck in SPACE showcase.</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#1-project-focus","title":"1. Project Focus","text":"<ul> <li>Exploration question or theme: Can AI help me generate safe medication dosage practice problems that align with first-year nursing competencies?</li> <li>Who benefits: My study group of 4 nursing students; potential future cohorts via SPACE site.</li> <li>Time window: 2025-09-15 \u2192 2025-10-05.</li> <li>Success looks like: A set of 6 practice cards with verified calculations and guidance on double-checking doses.</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#2-experiment-log","title":"2. Experiment Log","text":"Attempt Tool / Prompt What I tried What happened What I changed next 1 Claude \u2013 \"Create a dosage calc scenario for pediatric amoxicillin\" Generated scenario but incorrect mg/kg Flagged error; refined prompt to include weight range and check dose with formula 2 ChatGPT \u2013 \"List verification steps for insulin sliding scale\" Provided generic steps Added clinic-specific policy note and cross-checked with textbook 3 Claude \u2013 \"Draft three distractor answers for dosage math\" Two distractors unrealistic Adjusted to include rounding mistakes and unit conversion traps <ul> <li>Prompts, settings, resources to remember: Include dosage formula; remind AI to show calculation steps; cross-check with drug guide.</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#3-workflow-snapshot-after-refining","title":"3. Workflow Snapshot (after refining)","text":"Step AI Assist My Judgment Proof / Evidence 1 Claude drafts scenario + initial calculation I verify with dosage formula, note corrections Annotated prompt/output saved 2 Claude suggests distractors I adjust to realistic errors, add rationale Distractor table in deck 3 ChatGPT lists safety checks I tailor to our lab policy, add double-check steps Safety checklist slide"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#4-artifact-story","title":"4. Artifact &amp; Story","text":"<ul> <li>Artifact format: Google Slides deck (to export as PDF for SPACE).</li> <li>Key pieces: Scenario cards with final answers, verification notes, \"How to double-check\" section.</li> <li>AI + my contribution: AI drafted scenarios; I corrected math, contextualized policies, and added reflection prompts.</li> <li>Share plan: SPACE website submission + study group session.</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#5-reflection-prompts","title":"5. Reflection Prompts","text":"<ol> <li>AI sped up idea generation, letting me focus on verifying math and teaching classmates.</li> <li>AI helped brainstorm scenarios but sometimes miscalculated doses\u2014my nursing training caught mistakes.</li> <li>Next time I\u2019ll incorporate an instructor-approved calculator workflow and gather peer feedback on clarity.</li> </ol>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#6-integrity-verification","title":"6. Integrity &amp; Verification","text":"Output / Decision How I checked it Confidence Dosage answers Recalculated manually and with drug guide High Safety checklist Compared with course handbook and asked TA Medium Distractors Confirmed they matched common mistakes High <ul> <li>Questions for SPACE mentors/coordinators: Any guidance on presenting medication examples responsibly? Can I include a short video demo?</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#7-next-steps","title":"7. Next Steps","text":"<ul> <li>Next experiment: Pilot AI-generated simulation lab reflection prompts.</li> <li>Skills/resources to build: Faster verification method, multimedia storytelling.</li> <li>Feedback plan: Ask TA for review; invite study group to test cards; submit to SPACE forum.</li> </ul>"},{"location":"space/foundational/examples/nursing-study-guide/simulation/#prompt-boosters-optional","title":"Prompt Boosters (Optional)","text":"<ul> <li>Starter: \u201cCreate a medication dosage scenario for adult post-op pain management that avoids patient-specific identifiers.\u201d</li> <li>Optimizer: \u201cExplain the most likely mistake a student could make on this dosage problem and how to prevent it.\u201d</li> </ul>"},{"location":"use-cases/faculty-sandbox-use-cases/","title":"Use Cases","text":"<p>Quick Links: Faculty Sandbox | SPACE Sandbox | Resources | Orientation</p>"},{"location":"use-cases/faculty-sandbox-use-cases/#genai-sandbox-faculty-use-case-menu-draft","title":"GENAI Sandbox \u2013 Faculty Use Case Menu (Draft)","text":"<p>Last updated: 2025-09-21</p>"},{"location":"use-cases/faculty-sandbox-use-cases/#assessment-feedback","title":"Assessment &amp; Feedback","text":"<ol> <li>MCQ Generation &amp; Review (Mechanics): AI + SME workflow for crafting concept/quantitative questions with fair distractors, includes QA checklist and analytics loop (quickstart \u00b7 simulation).</li> <li>Code Review Assist (Intro Programming): Claude/ChatGPT aids student code revisions before instructor refinement; prototypes low-stakes feedback pipeline (quickstart \u00b7 simulation).</li> <li>Essay Feedback Calibration (Humanities): AI provides rubric-aligned high-level feedback, faculty refine tone and depth for cohort consistency.</li> </ol>"},{"location":"use-cases/faculty-sandbox-use-cases/#content-workflow-support","title":"Content &amp; Workflow Support","text":"<ol> <li>Workflow Snapshots for AI-Integrated Assignments (Humanities): AI summaries critiqued by students to deepen source analysis; delivers annotated workflow artifacts (quickstart \u00b7 simulation).</li> <li>Industrial Design Co-Designer (LLM + Lab Constraints): GPT-5 briefs and constraint checklists vetted by students/instructor to accelerate prototyping (quickstart \u00b7 simulation).</li> <li>Applied Arts Moodboard + Rationale (Archived): Midjourney/Firefly outputs annotated for brand alignment (available in archive for future reference \u2014 see <code>docs/examples/archive/</code>).</li> </ol>"},{"location":"use-cases/faculty-sandbox-use-cases/#lab-practical-prep-archived-optional","title":"Lab &amp; Practical Prep (Archived / Optional)","text":"<ol> <li>Physics Lab Pre-Brief (Archived): AI-generated pre-lab guidance with safety review; useful reference if lab teams revisit the idea (see <code>docs/examples/archive/</code>).</li> </ol>"},{"location":"use-cases/faculty-sandbox-use-cases/#emerging-ideas-to-explore","title":"Emerging Ideas to Explore","text":"<ol> <li>Rubric Calibration &amp; Peer Review: AI suggests exemplar responses, faculty adjust for clarity, then use in peer feedback training.</li> <li>Reflection Prompt Tailoring: AI drafts post-activity reflections based on tracked misconceptions; faculty decide where to deploy.</li> <li>Resource Menu Builder: AI curates topic-specific practice sets or reading lists, faculty validate and contextualize.</li> <li>Accessibility Audit Assist: AI identifies accessibility gaps (alt text, contrast) in digital teaching artifacts for quick faculty review.</li> </ol> <p>Use this menu during faculty brainstorms to identify quick wins and future pilots. Mark items as \u201cactive,\u201d \u201cbacklog,\u201d or \u201carchived\u201d based on cohort interest.</p>"},{"location":"workshops/template-spine-invite/","title":"Invite","text":"<p>Back to Faculty Sandbox | Resources: resources.md | Orientation: orientation-outline.md</p>"},{"location":"workshops/template-spine-invite/#invitation-streamlined-template-spine-drafting-workshop","title":"Invitation: Streamlined Template Spine Drafting Workshop","text":"<p>Meeting: GENAI Sandbox Documentation \u2013 Template Spine Draft When: Wednesday, October 22, 2025 \u00b7 1:00\u20132:00\u202fPM Eastern Where: Zoom (link to follow once calendar invite is sent) Organizer: John (PM)</p>"},{"location":"workshops/template-spine-invite/#participants","title":"Participants","text":"<ol> <li>UX/Content lead \u2013 primary copy/design partner</li> <li>Coordination representative \u2013 program requirements + tracker alignment</li> <li>Compliance reviewer (optional first 15 minutes) \u2013 confirm integrity/licensing language</li> </ol>"},{"location":"workshops/template-spine-invite/#purpose","title":"Purpose","text":"<ul> <li>Align on the new Goal \u2192 Workflow Snapshot \u2192 Evidence \u2192 Reflection \u2192 Disclosure template structure.</li> <li>Draft the shared governance preface and verification log table that will appear across artifacts.</li> <li>Outline the one-page quickstart and exemplar requirements so drafting can proceed immediately after the session.</li> </ul>"},{"location":"workshops/template-spine-invite/#pre-read-preparation","title":"Pre-Read &amp; Preparation","text":"<ul> <li>Review <code>docs/genai-sandbox-docs-spec.md</code> (Sections 2\u20136) for scope, constraints, and success metrics.</li> <li>Skim the archived brownfield templates in <code>docs/archive/brownfield-templates-2024/</code> to identify any content we must carry forward.</li> <li>Gather department-specific terminology or compliance notes that should influence prompts or headers.</li> </ul>"},{"location":"workshops/template-spine-invite/#agenda-snapshot","title":"Agenda Snapshot","text":"<ol> <li>Welcome, goals, and constraint recap (5 min)</li> <li>Template spine whiteboard draft (20 min)</li> <li>Governance preface + verification log copy (15 min)</li> <li>Reflection prompts + quickstart outline (10 min)</li> <li>Action assignments &amp; next steps (10 min)</li> </ol>"},{"location":"workshops/template-spine-invite/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Drafted section sequence with placeholder copy blocks.</li> <li>Agreed responsibilities for fleshing out template text, exemplars, and quickstart page.</li> <li>List of open questions to park for follow-up (e.g., compliance clarifications, exemplar sourcing).</li> </ul>"},{"location":"workshops/template-spine-invite/#next-actions-post-workshop","title":"Next Actions Post-Workshop","text":"<ul> <li>PM circulates notes within 48 hours and logs action items.</li> <li>Track progress via monthly pulse survey; flag blockers early given limited coordination bandwidth.</li> </ul> <p>Please confirm attendance or send a delegate by October 10, 2025 so we can keep the session tight and productive.</p>"},{"location":"workshops/template-spine-preread/","title":"Preread","text":"<p>Back to Faculty Sandbox | Resources: resources.md | Orientation: orientation-outline.md</p>"},{"location":"workshops/template-spine-preread/#pre-read-streamlined-template-spine-workshop","title":"Pre-Read: Streamlined Template Spine Workshop","text":"<p>Session: Wed, Oct 22, 2025 \u00b7 1:00\u20132:00\u202fPM ET Objective: Shape exploration-first documentation for the GENAI Sandbox.</p>"},{"location":"workshops/template-spine-preread/#why-were-meeting","title":"Why We\u2019re Meeting","text":"<ul> <li>Align on a lean Goal \u2192 Workflow \u2192 Evidence \u2192 Reflection \u2192 Disclosure spine that celebrates experimentation.</li> <li>Keep governance as a supportive guideline, not the lead story.</li> <li>Ensure faculty, student, and coordination needs flow from the sandbox concept before classroom rollout.</li> </ul>"},{"location":"workshops/template-spine-preread/#required-reading-15-min-total","title":"Required Reading (15 min total)","text":"<ol> <li><code>docs/genai-sandbox-docs-spec.md</code> \u2014 focus on Sections 2\u20134 &amp; 6 for scope, users, constraints.</li> <li><code>docs/quickstart-outline.md</code> \u2014 note how we\u2019re framing the exploration journey.</li> <li><code>docs/archive/brownfield-templates-2024/INDEX.md</code> (skim) \u2014 reminder of the legacy pieces we\u2019re superseding.</li> </ol>"},{"location":"workshops/template-spine-preread/#bring-with-you","title":"Bring With You","text":"<ul> <li>Department/discipline terminology or stories that highlight sandbox experimentation.</li> <li>Any must-keep prompts or fields from the brownfield templates (flag why they matter).</li> <li>One idea for how quickstart guardrails can stay supportive yet unobtrusive.</li> </ul>"},{"location":"workshops/template-spine-preread/#discussion-anchors","title":"Discussion Anchors","text":"<ul> <li>How do we make the template feel like an invitation to explore, not a compliance form?</li> <li>Where should exemplar entries live so participants can learn from past experiments without extra meetings?</li> <li>What\u2019s the lightest-weight way to capture verification without slowing momentum?</li> </ul>"},{"location":"workshops/template-spine-preread/#outputs-we-expect","title":"Outputs We Expect","text":"<ul> <li>First-pass template structure reflecting the quickstart flow.</li> <li>Draft language for the governance guardrail box.</li> <li>Owner list for exemplar samples, quickstart copy, and follow-up questions.</li> </ul> <p>Come ready to sketch, iterate, and keep the sandbox playful before we lock in production-ready documents.</p>"},{"location":"workshops/template-spine-workshop/","title":"Agenda","text":"<p>Back to Faculty Sandbox | Resources: resources.md | Orientation: orientation-outline.md</p>"},{"location":"workshops/template-spine-workshop/#streamlined-template-spine-drafting-workshop-plan","title":"Streamlined Template Spine \u2013 Drafting Workshop Plan","text":"<p>Target Date: 2025-10-22 \u00b7 13:00\u201314:00 ET (60 minutes) Facilitator: PM (John) Participants: - UX/Content lead - Coordination representative - Learning strategist or peer facilitator (optional, first 15 minutes)</p>"},{"location":"workshops/template-spine-workshop/#objectives","title":"Objectives","text":"<ol> <li>Draft the consolidated template spine (Goal \u2192 Workflow Snapshot \u2192 Evidence \u2192 Reflection \u2192 Disclosure) with exploration-first framing.</li> <li>Translate the quickstart outline into template copy blocks, keeping governance as lightweight guardrails.</li> <li>Define requirements for exemplar tables, optional guidelines, and next-step prompts that encourage continued discovery.</li> </ol>"},{"location":"workshops/template-spine-workshop/#pre-work","title":"Pre-Work","text":"<ul> <li>Review <code>docs/genai-sandbox-docs-spec.md</code> sections 2\u20136.</li> <li>Skim archived brownfield templates (now in <code>docs/archive/brownfield-templates-2024/</code>) to note must-keep elements.</li> <li>Read <code>docs/quickstart-outline.md</code> and flag any additions needed for exploration storytelling.</li> <li>Bring department-specific terminology or discovery examples that should inform adaptable headers.</li> </ul>"},{"location":"workshops/template-spine-workshop/#agenda","title":"Agenda","text":"<ol> <li>Opening &amp; Goals (5 min) \u2013 Align on exploration-first outcomes and constraints.</li> <li>Template Spine Sketch (20 min) \u2013 Map section order, prompts, and required fields with sandbox storytelling in mind.</li> <li>Quickstart &amp; Governance Touchpoints (15 min) \u2013 Translate quickstart outline into copy; embed concise guardrails and verification notes.</li> <li>Reflection &amp; Next Experiment Hooks (10 min) \u2013 Finalize three-question reflection and capture prompts that encourage future iterations.</li> <li>Action Items &amp; Next Steps (10 min) \u2013 Assign drafting tasks, review timelines, capture open questions.</li> </ol>"},{"location":"workshops/template-spine-workshop/#expected-outputs","title":"Expected Outputs","text":"<ul> <li>Draft template outline captured in shared document (to be transferred into markdown post-session).</li> <li>Action list with owners for: template copywriting, exemplar creation, quickstart refinement, facilitator check-ins.</li> <li>Identified terminology adaptations and discovery examples per department (to inform persona-specific prompts).</li> </ul>"},{"location":"workshops/template-spine-workshop/#follow-up","title":"Follow-Up","text":"<ul> <li>PM consolidates workshop notes within 48 hours and circulates to participants.</li> <li>Schedule check-in during next monthly pulse to confirm drafting progress and integrate feedback.</li> </ul>"}]}